\chapter{Aspekte von Go}\label{ch:method}

\section{Compiler und Dinge wie Scanner und Parser, Semantische Analyse}
\subsection{Scanner(Lexical Analysis)}
In der Syntax.go Datei wird die Funktion Parse definiert. Diese Definiert einen Parser und ruft dann dessen Initialisierungsfunktion auf. Danach wird der Parser auf das nächste Token geschalten. 
Der Parser ruft die Scanner init- Funktion auf. Der Scanner selbst ist definiert in der scanner.go Datei, der Parser hingegen in der Parser.Go Datei. Alle drei Dateien sind in dem Ordner src/cmd/compile/internal/syntax. 
\cite{donovan_go_2016}
\begin{lstlisting}
// The mode flags below control which comments are reported
// by calling the error handler. If no flag is set, comments
// are ignored.
const (
	comments   uint = 1 << iota // call handler for all comments
	directives                  // call handler for directives only
)

type scanner struct {
	source
	mode   uint
	nlsemi bool // if set '\n' and EOF translate to ';'

	// current token, valid after calling next()
	line, col uint
	blank     bool // line is blank up to col
	tok       token
	lit       string   // valid if tok is _Name, _Literal, or _Semi ("semicolon", "newline", or "EOF"); may be malformed if bad is true
	bad       bool     // valid if tok is _Literal, true if a syntax error occurred, lit may be malformed
	kind      LitKind  // valid if tok is _Literal
	op        Operator // valid if tok is _Operator, _Star, _AssignOp, or _IncOp
	prec      int      // valid if tok is _Operator, _Star, _AssignOp, or _IncOp
}
\end{lstlisting}
Der Scanner besitzt einige Felder zum identifizieren von Token. 
Source wird mit dem IO Stream des zu scannenden Textes übergeben.
Die mode flags kontrollieren welche Kommentare als Fehler geflaged werden. 
Bei nicht Setzung werden alle Kommentare ignoriert. Bei Setzen auf 1 werden alle Kommentare an den Error Handler übergeben, bei Setzen auf 2 nur die directives. Directives in Go sind spezifische Compiler Instruktionen, die ebenfalls mit // beginnen. Diese können überallhin platziert werden. Die Syntax ist //go:directive. Pragmas und Directives sind Synonyme. Benutzen von diesen ist generell eher unerwünscht.
NlSemi bestimmt, ob \escape{n} und das Ende des Files zu ; übersetzt werden. Dies hat den Vorteil, dass manuell keine Strichpunkte mehr gesetzt werden müssen, da der Kompiler dies automatisch tut in jeder Neuen Zeile. Hier kann es aber zu Einschränkungen kommen. Geschweifte Klammern nach Kontrollstrukturen(if,switch) können nicht in die nächste Zeile gesetzt werden, da sonst ein Strichpunkt vom Compiler dahinter gesetzt werden würde. Eine einzelne geschweifte Klammer ist ein ungültiges Statement. Somit muss die geschweifte Klammer immer in der gleichen Zeile wie die Kontrollstruktur sein, da diese dort erwartet wird. 
Line und col ist die aktuelle Position des gelesenen Characters. Blank??????. Tok ist das resultierende Token. Lit wird benutzt, um zwischenzuspeichern, falls ein Name, ein Literal oder eine der drei Semicolon Fälle auftreten. Bad wird benutzt um zu kennzeichen, dass ein Syntax Error aufgetreten ist. Kind beschreibt die Art des Literals, falls dieses auftritt. Op und Prec speichern Werte, falls ein Operator, Star, AssignOp oder IncOp Token auftritt.

\begin{lstlisting}
// hash is a perfect hash function for keywords.
// It assumes that s has at least length 2.
func hash(s []byte) uint {
	return (uint(s[0])<<4 ^ uint(s[1]) + uint(len(s))) & uint(len(keywordMap)-1)
}

var keywordMap [1 << 6]token // size must be power of two

func init() {
	// populate keywordMap
	for tok := _Break; tok <= _Var; tok++ {
		h := hash([]byte(tok.String()))
		if keywordMap[h] != 0 {
			panic("imperfect hash")
		}
		keywordMap[h] = tok
	}
}

	// keywords(defined in tokens.go File)
	_Break       // break
	_Case        // case
	_Chan        // chan
	_Const       // const
	_Continue    // continue
	_Default     // default
	_Defer       // defer
	_Else        // else
	_Fallthrough // fallthrough
	_For         // for
	_Func        // func
	_Go          // go
	_Goto        // goto
	_If          // if
	_Import      // import
	_Interface   // interface
	_Map         // map
	_Package     // package
	_Range       // range
	_Return      // return
	_Select      // select
	_Struct      // struct
	_Switch      // switch
	_Type        // type
	_Var         // var
\end{lstlisting}
Folgende Funktionen werden für die Initialisierung einer Keyword map benutzt, die später benötigt wird um zu testen, ob ein es sich um ein Keyword Token handelt. Zunächst werden alle möglichen Keywords als Constant strings definiert und in der Datei token\_string.go einen Int Wert zugewiesen, der sich pro Zeile um eins inkrementiert. Somit werden in der For Schleife alle Keywords durchlaufen und für jedes an einer Stelle gepspeichert. Diese Stelle wird mit einer Hash Funktion generiert, die Kollisionen vermeiden soll.

Die Funktion next liest den nächsten Token. Zuerst wird ein lokales nlsemi erstellt, dass auf das nlsemi des Scanners gesetzt wird. Dieses wird dann auf falsch gesetzt. Das Label redo und das Label assignop wird definiert. Danach werden alle whitespace Character übersprungen. Der Scanner wird auf den Start des tatsächlichen Tokens eingestellt. Einige Fälle werden vorher seperat abgedeckt. Momentan wird sich der erste Character des Token angeschaut. 
\begin{lstlisting}
func (s *scanner) atIdentChar(first bool) bool {
	switch {
	case unicode.IsLetter(s.ch) || s.ch == '_':
		// ok
	case unicode.IsDigit(s.ch):
		if first {
			s.errorf("identifier cannot begin with digit %#U", s.ch)
		}
	case s.ch >= utf8.RuneSelf:
		s.errorf("invalid character %#U in identifier", s.ch)
	default:
		return false
	}
	return true
}
\end{lstlisting}
Die Funktion atIdentChar bestimmt, dass ein Token nicht mit einer Zahl beginnen darf. Buchstaben oder '\_' sind dort in Ordnung. Wenn der Character größer als utf8.RuneSelf ist, dann wird davon ausgegangen, dass ist der Character außerhalb der gültigen Zeichen. In beiden Fällen wird ein Fehler ausgegeben. Werden diese Regeln eingehalten, dann kann sich der nächste Character angeschaut werden.
\begin{lstlisting}
    func (s *scanner) ident() {
	// accelerate common case (7bit ASCII)
	for isLetter(s.ch) || isDecimal(s.ch) {
		s.nextch()
	}

	// general case
	if s.ch >= utf8.RuneSelf {
		for s.atIdentChar(false) {
			s.nextch()
		}
	}

	// possibly a keyword
	lit := s.segment()
	if len(lit) >= 2 {
		if tok := keywordMap[hash(lit)]; tok != 0 && tokStrFast(tok) == string(lit) {
			s.nlsemi = contains(1<<_Break|1<<_Continue|1<<_Fallthrough|1<<_Return, tok)
			s.tok = tok
			return
		}
	}

	s.nlsemi = true
	s.lit = string(lit)
	s.tok = _Name
}
\end{lstlisting}
Für die nächsten Character wird die Funktion ident benutzt. Solange auf den ersten Character Buchstaben und Zahlen folgen, wird der Character übersprungen. Wenn das Zeichen ungültig ist weil es größer als utf8.RuneSelf ist, dann wird ebenfalls wieder ein Fehler ausgegeben. 
Wenn das Wort zu Ende ist, wird geprüft ob es mehr als einen Character hat. Ist dies der Fall, hat man ein Keyword gefunden und das Token wird dementsprechend gesetzt.\\
\\Weiterhin folgen einige speziellere Fälle, die mit einem Switch Case Statement durchlaufen werden. Diese lassen sich weiter aufteilen in die Kommentare und Pragmas, Operatoren Zeichen und zu Letzt alle weiteren Zeichen, die benutzt werden.  
\begin{lstlisting}
case '/':
		s.nextch()
		if s.ch == '/' {
			s.nextch()
			s.lineComment()
			goto redo
		}
		if s.ch == '*' {
			s.nextch()
			s.fullComment()
			if line, _ := s.pos(); line > s.line && nlsemi {
				// A multi-line comment acts like a newline;
				// it translates to a ';' if nlsemi is set.
				s.lit = "newline"
				s.tok = _Semi
				break
			}
			goto redo
		}
		s.op, s.prec = Div, precMul
		goto assignop

\end{lstlisting}
Für den einzeiligen Kommentar // wird die Funktion lineComment aufgerufen.
\begin{lstlisting}
func (s *scanner) lineComment() {

	if s.mode&comments != 0 {
		s.skipLine()
		s.comment(string(s.segment()))
		return
	}

	// are we saving directives? or is this definitely not a directive?
	if s.mode&directives == 0 || (s.ch != 'g' && s.ch != 'l') {
		s.stop()
		s.skipLine()
		return
	}

	// recognize go: or line directives
	prefix := "go:"
	if s.ch == 'l' {
		prefix = "line "
	}
	for _, m := range prefix {
		if s.ch != m {
			s.stop()
			s.skipLine()
			return
		}
		s.nextch()
	}

	// directive text
	s.skipLine()
	s.comment(string(s.segment()))
}
\end{lstlisting}
Ist mode so gesetzt, dass Kommentare Fehler zurückgeben, wird dies hier getan mit der Funktion comment. Zusätzlich muss skipLine aufgerufen werden. Diese Funktion stellt sicher, dass der Character \\n übersprungen wird. Dieser wird benötigt, um die Logik für nlsemi umzusetzen. Wenn mode auf nur Directives gesetzt ist, wird überprüft ob es sich um eine handelt. Diese müsste mit //go: oder mit \\l (für \\line:) starten. Ist dies nicht der Fall, wird die Funktion stop aufgerufen. Wenn eine Directive erkannt, wird diese als Fehler zurückgegeben.\\
\\Mehrzeilige Kommentare werden genauso behandelt wie eine neue Zeile. Ein Unterschied ist in der Full Comment Funktion.
\begin{lstlisting}
// recognize line directive
	const prefix = "line "
	for _, m := range prefix {
		if s.ch != m {
			s.stop()
			s.skipComment()
			return
		}
		s.nextch()
	}
\end{lstlisting}
Hier muss auf die line Directive geachtet werden.\\
\\Ist kein // vorhanden sondern nur ein einzelner /, muss es sich um einen Operator handeln und dementsprechend wird dorthin gesprungen. 

\begin{lstlisting}
case '\n':
		s.nextch()
		s.lit = "newline"
		s.tok = _Semi
\end{lstlisting}
Neue Zeilen werden so direkt eingelesen
\begin{lstlisting}
	case '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':
		s.number(false)
        
    func (s *scanner) number(seenPoint bool) {
	ok := true
	kind := IntLit
	base := 10        // number base
	prefix := rune(0) // one of 0 (decimal), '0' (0-octal), 'x', 'o', or 'b'
	digsep := 0       // bit 0: digit present, bit 1: '_' present
	invalid := -1     // index of invalid digit in literal, or < 0

	// integer part
	if !seenPoint {
		if s.ch == '0' {
			s.nextch()
			switch lower(s.ch) {
			case 'x':
				s.nextch()
				base, prefix = 16, 'x'
			case 'o':
				s.nextch()
				base, prefix = 8, 'o'
			case 'b':
				s.nextch()
				base, prefix = 2, 'b'
			default:
				base, prefix = 8, '0'
				digsep = 1 // leading 0
			}
		}
		digsep |= s.digits(base, &invalid)
		if s.ch == '.' {
			if prefix == 'o' || prefix == 'b' {
				s.errorf("invalid radix point in %s literal", baseName(base))
				ok = false
			}
			s.nextch()
			seenPoint = true
		}
	}
\end{lstlisting}
Da Zahlen an Erster Stelle bereits behandelt wurden handelt es sich hier um eine weitere Ziffer. Somit muss hier entschieden werden, ob es sich um eine Kommazahl handelt. Ist eine weitere Ziffer erkannt, handelt es sich momentan um keine Kommazahl und die Funktion Number wird dementsprechend aufgerufen. In dieser wird standardmäßig die Basis als Dezimalzahl behandelt. Dies muss geändert werden, wenn auf den Character 0 ein weitere Character folgt, der keine Zahl ist. Für das Hexadezimal System ist dies x, für das Oktalsystem o und für das Binärsystem b. Digsep sagt aus ob ein Seperator vorhanden ist. 
Nach dem Richtigstellen der Basis, wird ein bitweises OR von digsep mit der Funktion digits durchgeführt. Diese Funktion gibt eine Zahl zurück, deren Bitmuster aussagt, ob ein Seperator vorhanden ist oder nicht. Ist das nullte Bit auf eins gesetzt, sind Zahlen vorhanden. Ist das erste Bit auf eins gesetzt, sind Seperatoren vorhanden. Wenn die Funktion die Integer Zahl drei zurückgibt, sind beide dieser Bits gesetzt und somit sind Zahlen und Seperatoren vorhanden. Dieses wird dann an die lokale dipsep Variable übertragen. Wenn der Seperator ein Dezimalpunkt ist, wird ein Fehler ausgegeben wenn die Zahl eine Oktal- oder Binärzahl ist. Daraufhin wird die Variable seenPoint auf true gesetzt und die es handelt sich um eine Kommazahl.
\begin{lstlisting}
if seenPoint {
		kind = FloatLit
		digsep |= s.digits(base, &invalid)
	}

	if digsep&1 == 0 && ok {
		s.errorf("%s literal has no digits", baseName(base))
		ok = false
	}
\end{lstlisting}
Wenn ein Punkt existiert, wird kind auf die Existenz eines Float Literals gesetzt. Standardmäßig ist dies auf IntLit also auf literals gesetzt, die bei Integer Zahlen vorkommen.
Wenn das nullte Bit auf null gesetzt ist das erste Bit aber auf eins, hier geprüft durch die Variable ok, dann gibt es einen Fehler da keine Zahlen und nur Seperatoren gefunden wurden.
\begin{lstlisting}
if e := lower(s.ch); e == 'e' || e == 'p' {
		if ok {
			switch {
			case e == 'e' && prefix != 0 && prefix != '0':
				s.errorf("%q exponent requires decimal mantissa", s.ch)
				ok = false
			case e == 'p' && prefix != 'x':
				s.errorf("%q exponent requires hexadecimal mantissa", s.ch)
				ok = false
			}
		}
		s.nextch()
		kind = FloatLit
		if s.ch == '+' || s.ch == '-' {
			s.nextch()
		}
		digsep = s.digits(10, nil) | digsep&2 // don't lose sep bit
		if digsep&1 == 0 && ok {
			s.errorf("exponent has no digits")
			ok = false
		}
	} else if prefix == 'x' && kind == FloatLit && ok {
		s.errorf("hexadecimal mantissa requires a 'p' exponent")
		ok = false
	}
\end{lstlisting}
Um Exponenten auszudrücken werden die Character e und p benutzt. Wenn der Character e vorhanden ist, muss die Zahl(Mantisse) vor dem Exponent eine Dezimalzahl sein. Wenn p benutzt wird, muss es eine Hexadezimalzahl sein.
Bei + oder - wird der Character übersprungen. Hier wird ebenfalls geprüft, ob nur Seperatoren und keine Zahlen vorhanden sind. Zusätzlich wird gefordert, dass eine Hexadezimalzahl einen Exponenten mit dem Character p startet. Der Character i kann ebenfalls noch vorkommen und in dem Fall gesetzt. 

Wenn eine Ziffer ungültig war, wird dieser Fall am Schlus geprüft und als Fehler ausgegeben. Ebenso wird mit der Hilfe invalidSep der erste ungültige Seperator ausgegeben. \\
\\
\begin{lstlisting}
case '(':
		s.nextch()
		s.tok = _Lparen

	case '[':
		s.nextch()
		s.tok = _Lbrack

	case '{':
		s.nextch()
		s.tok = _Lbrace

	case ',':
		s.nextch()
		s.tok = _Comma

	case ';':
		s.nextch()
		s.lit = "semicolon"
		s.tok = _Semi

	case ')':
		s.nextch()
		s.nlsemi = true
		s.tok = _Rparen

	case ']':
		s.nextch()
		s.nlsemi = true
		s.tok = _Rbrack

	case '}':
		s.nextch()
		s.nlsemi = true
		s.tok = _Rbrace
\end{lstlisting}
Klammern aller Art, das Komma und der Strichpunkt werden alle gekennzeichnet.
\begin{lstlisting}
	case ':':
		s.nextch()
		if s.ch == '=' {
			s.nextch()
			s.tok = _Define
			break
		}
		s.tok = _Colon
\end{lstlisting}
Der Doppelpunkt wird als Dopplepunkt gekennzeichnet, außer wenn darauf ein Istgleich Zeichen folgt. Dies ist der Define Operator, mit welchem Variablen definiert werden können.
\begin{lstlisting}
	case '.':
		s.nextch()
		if isDecimal(s.ch) {
			s.number(true)
			break
		}
		if s.ch == '.' {
			s.nextch()
			if s.ch == '.' {
				s.nextch()
				s.tok = _DotDotDot
				break
			}
			s.rewind() // now s.ch holds 1st '.'
			s.nextch() // consume 1st '.' again
		}
		s.tok = _Dot
\end{lstlisting}
Der Punkt wird als Kommapunkt gewertet, wenn darauf eine Dezimalzahl folgt. Wenn zwei weitere Punkte folgen wird es als ... Operator erkannt. Dieser wird die Definition einer variablen Anzahl von Parametern benutzt. Ansonsten wird es als Punkt gewertet, der z.B bei Zugriff auf Typ Methoden eingesetzt wird.\\
\\ Ein weitere größere Unterteilung bilden die Operatoren. Beginnend mit den Standardoperatoren + und -.
\begin{lstlisting}
case '+':
		s.nextch()
		s.op, s.prec = Add, precAdd
		if s.ch != '+' {
			goto assignop
		}
		s.nextch()
		s.nlsemi = true
		s.tok = _IncOp

	case '-':
		s.nextch()
		s.op, s.prec = Sub, precAdd
		if s.ch != '-' {
			goto assignop
		}
		s.nextch()
		s.nlsemi = true
		s.tok = _IncOp
\end{lstlisting}
Wenn nur ein einzelnes Zeichen existiert, wird zum Label AssignOp gesprungen.
\begin{lstlisting}
assignop:
	if s.ch == '=' {
		s.nextch()
		s.tok = _AssignOp
		return
	}
	s.tok = _Operator
\end{lstlisting}
Dieses prüft, ob es sich um den AssignOpertor handelt. Wenn nicht wird einfach nur der Token auf Operator gesetzt.\\
Kommen zwei + oder zwei - vor, dann wird dieses als Increment oder als Decrement Operator gewertet, der jeweils +1 oder -1 auf eine Variable rechnet.
\begin{lstlisting}
    case '*':
		s.nextch()
		s.op, s.prec = Mul, precMul
		// don't goto assignop - want _Star token
		if s.ch == '=' {
			s.nextch()
			s.tok = _AssignOp
			break
		}
		s.tok = _Star

	case '/':
		s.nextch()
		if s.ch == '/' {
			s.nextch()
			s.lineComment()
			goto redo
		}
		if s.ch == '*' {
			s.nextch()
			s.fullComment()
			if line, _ := s.pos(); line > s.line && nlsemi {
				// A multi-line comment acts like a newline;
				// it translates to a ';' if nlsemi is set.
				s.lit = "newline"
				s.tok = _Semi
				break
			}
			goto redo
		}
		s.op, s.prec = Div, precMul
		goto assignop
\end{lstlisting}
Wenn auf * oder / ein = folgt, dann wird dieses als Assign Operator gewertet. Für * wird extra das Token auf \_Star gesetzt. Für / wird der Assign Operator bei AssignOp gesetzt.
\begin{lstlisting}
	case '%':
		s.nextch()
		s.op, s.prec = Rem, precMul
		goto assignop
    case '^':
		s.nextch()
		s.op, s.prec = Xor, precAdd
		goto assignop
    
	case '~':
		s.nextch()
		s.op, s.prec = Tilde, 0
		s.tok = _Operator
\end{lstlisting}
Für die Operatoren \%, \^ und \~ werden nur die jeweiligen Operator Token gesetzt.
\begin{lstlisting}
case '<':
		s.nextch()
		if s.ch == '=' {
			s.nextch()
			s.op, s.prec = Leq, precCmp
			s.tok = _Operator
			break
		}
		if s.ch == '<' {
			s.nextch()
			s.op, s.prec = Shl, precMul
			goto assignop
		}
		if s.ch == '-' {
			s.nextch()
			s.tok = _Arrow
			break
		}
		s.op, s.prec = Lss, precCmp
		s.tok = _Operator

	case '>':
		s.nextch()
		if s.ch == '=' {
			s.nextch()
			s.op, s.prec = Geq, precCmp
			s.tok = _Operator
			break
		}
		if s.ch == '>' {
			s.nextch()
			s.op, s.prec = Shr, precMul
			goto assignop
		}
		s.op, s.prec = Gtr, precCmp
		s.tok = _Operator
\end{lstlisting}
< und > haben decken folgende Operatoren Fälle ab: >= und <=, >> und <<, zuletzt <-. 
\begin{lstlisting}
case '&':
		s.nextch()
		if s.ch == '&' {
			s.nextch()
			s.op, s.prec = AndAnd, precAndAnd
			s.tok = _Operator
			break
		}
		s.op, s.prec = And, precMul
		if s.ch == '^' {
			s.nextch()
			s.op = AndNot
		}
		goto assignop
case '|':
		s.nextch()
		if s.ch == '|' {
			s.nextch()
			s.op, s.prec = OrOr, precOrOr
			s.tok = _Operator
			break
		}
		s.op, s.prec = Or, precAdd
		goto assignop
\end{lstlisting}
Für | und \& werden sowohl die einzelnen Logik Operatoren als auch die doppelten \&\& und || zugewiesen. Zusätzlich existiert nicht der AndNot Operator \&\^.
\begin{lstlisting}
	case '=':
		s.nextch()
		if s.ch == '=' {
			s.nextch()
			s.op, s.prec = Eql, precCmp
			s.tok = _Operator
			break
		}
		s.tok = _Assign

	case '!':
		s.nextch()
		if s.ch == '=' {
			s.nextch()
			s.op, s.prec = Neq, precCmp
			s.tok = _Operator
			break
		}
		s.op, s.prec = Not, 0
		s.tok = _Operator

\end{lstlisting}
Zuletzt gibt es noch den Equal Operator ==, der im Fall eines einzelnen = ein Assign Operator ist. Für ! existiert der Not Operator ! und der Not Equal Operator !=. \\
\\ Zuletzt werden noch die String Methoden " ' und ` mit jeweils eigenen Methoden erkannt.
\begin{lstlisting}
	case '"':
		s.stdString()

	case '`':
		s.rawString()

	case '\'':
		s.rune()

func (s *scanner) stdString() {
	ok := true
	s.nextch()

	for {
		if s.ch == '"' {
			s.nextch()
			break
		}
		if s.ch == '\\' {
			s.nextch()
			if !s.escape('"') {
				ok = false
			}
			continue
		}
		if s.ch == '\n' {
			s.errorf("newline in string")
			ok = false
			break
		}
		if s.ch < 0 {
			s.errorAtf(0, "string not terminated")
			ok = false
			break
		}
		s.nextch()
	}

	s.setLit(StringLit, ok)
\end{lstlisting}
Für den Standard String "" werden einige Fälle definiert. Wenn direkt der zweite " folgt dann ist es der leere String und es kann abgebrochen werden. Falls ein Backslash in dem String alleine vorkommt, ist dies ein Escape Zeichen und die Funktion wird aufgerufen. In diesem Fall gibt diese aber nur true zurück. 
Existiert ein Whitespace in dem String wird ein Fehler ausgeworfen, dass eine neue Zeile im String enthalten ist. Falls kein zweites " mehr folgt, wird der Fehler ausgeworfen dass der String nicht terminiert wurde.
\begin{lstlisting}
func (s *scanner) rawString() {
	ok := true
	s.nextch()

	for {
		if s.ch == '`' {
			s.nextch()
			break
		}
		if s.ch < 0 {
			s.errorAtf(0, "string not terminated")
			ok = false
			break
		}
		s.nextch()
	}
	// We leave CRs in the string since they are part of the
	// literal (even though they are not part of the literal
	// value).

	s.setLit(StringLit, ok)
}
\end{lstlisting}
Für den raw String existiert der leere String `` oder der nicht terminierte String.
\begin{lstlisting}
unc (s *scanner) rune() {
	ok := true
	s.nextch()

	n := 0
	for ; ; n++ {
		if s.ch == '\'' {
			if ok {
				if n == 0 {
					s.errorf("empty rune literal or unescaped '")
					ok = false
				} else if n != 1 {
					s.errorAtf(0, "more than one character in rune literal")
					ok = false
				}
			}
			s.nextch()
			break
		}
		if s.ch == '\\' {
			s.nextch()
			if !s.escape('\'') {
				ok = false
			}
			continue
		}
		if s.ch == '\n' {
			if ok {
				s.errorf("newline in rune literal")
				ok = false
			}
			break
		}
		if s.ch < 0 {
			if ok {
				s.errorAtf(0, "rune literal not terminated")
				ok = false
			}
			break
		}
		s.nextch()
	}
\end{lstlisting}
Für die rune Funktion gibt es ähnliche Fälle. Die leere Rune ist nicht gültig. Somit wird dies geprüft genauso wei der Fall wenn mehr als ein Character in einer Rune enthalten ist. Weiterhin gibt es den Escape mit Backslash, die Neue Zeile mit Whitespace und den Fall dass das Rune literal nicht terminiert wurde.
\begin{lstlisting}
p.scanner.init(
		r,
		// Error and directive handler for scanner.
		// Because the (line, col) positions passed to the
		// handler is always at or after the current reading
		// position, it is safe to use the most recent position
		// base to compute the corresponding Pos value.
		func(line, col uint, msg string) {
			if msg[0] != '/' {
				p.errorAt(p.posAt(line, col), msg)
				return
			}

			// otherwise it must be a comment containing a line or go: directive.
			// //line directives must be at the start of the line (column colbase).
			// /*line*/ directives can be anywhere in the line.
			text := commentText(msg)
			if (col == colbase || msg[1] == '*') && strings.HasPrefix(text, "line ") {
				var pos Pos // position immediately following the comment
				if msg[1] == '/' {
					// line comment (newline is part of the comment)
					pos = MakePos(p.file, line+1, colbase)
				} else {
					// regular comment
					// (if the comment spans multiple lines it's not
					// a valid line directive and will be discarded
					// by updateBase)
					pos = MakePos(p.file, line, col+uint(len(msg)))
				}
				p.updateBase(pos, line, col+2+5, text[5:]) // +2 to skip over // or /*
				return
			}

			// go: directive (but be conservative and test)
			if strings.HasPrefix(text, "go:") {
				if p.top && strings.HasPrefix(msg, "//go:build") {
					if x, err := constraint.Parse(msg); err == nil {
						p.goVersion = constraint.GoVersion(x)
					}
				}
				if pragh != nil {
					p.pragma = pragh(p.posAt(line, col+2), p.scanner.blank, text, p.pragma) // +2 to skip over // or /*
				}
			}
		},
		directives,
	)

	p.base = file
	p.first = nil
	p.errcnt = 0
	p.pragma = nil

	p.fnest = 0
	p.xnest = 0
	p.indent = nil
}
\end{lstlisting}
Bevor der Parser übernimmt, wird in dem parser.go File der Scanner initialisiert. Hierzu wird als Source der Io Reader genutzt, der dem Parser übergeben wurde. Als nächstes müssen Error und Directive Handler definiert werden. Für den Error Handler reicht eine einfacher Prüfung, ob eine Nachricht gesetzt wurde. Dann kann ein Fehler mit aktueller Position ausgegeben werden. Für den Directive Handler wird zuerst nach line( //line) Directives geprüft. Dazu muss die Directive am Anfang der Linie starten. Somit muss die aktuelle Spalte der Spaltenbasis gleichen oder die msg enthalt einen Stern an zweiter Positon, um die Directive /*line*/ abzudecken, die überall in der Zeile vorkommen kann. Funktion MakePos findet die Position nach dem Ende der Directive und aktualisiert pos. Update Base kümmert sich um die Aktualisierung der Positionsbasis, die Feld des Parsers ist. Danach werden die directives übergeben.Ab hier übernimmt nun der Parser.

\subsection{Parser(Syntactic and Semantic Analysis)}
\subsection{Parsing}
Der Parser beginnt in der Parser init funktion die internen Variablen auf die Startwerte zu setzen.
\begin{lstlisting}
type parser struct {
	file  *PosBase
	errh  ErrorHandler
	mode  Mode
	pragh PragmaHandler
	scanner

	base      *PosBase // current position base
	first     error    // first error encountered
	errcnt    int      // number of errors encountered
	pragma    Pragma   // pragmas
	goVersion string   // Go version from //go:build line

	top    bool   // in top of file (before package clause)
	fnest  int    // function nesting level (for error handling)
	xnest  int    // expression nesting level (for complit ambiguity resolution)
	indent []byte // tracing support
}
\end{lstlisting}

Die Variable scanner ist der davor initialiserte Scanner.
Der Source Code wird zu Token aufgeteilt(lexical analysis) und geparsed(syntax analysis). Daraufhin entsteht ein Syntax Tree für jedes einzelne File.  
\begin{lstlisting}

type Mode uint

const (
	CheckBranches Mode = 1 << iota // check correct use of labels, break, continue, and goto statements
)

type Error struct {
	Pos Pos
	Msg string
}

func (err Error) Error() string {
	return fmt.Sprintf("%s: %s", err.Pos, err.Msg)
}

var _ error = Error{} // verify that Error implements error

type ErrorHandler func(err error)

type Pragma interface{}
\end{lstlisting}
Am Anfang des Syntax.Go Dokuments werden einige benötigte Typen definiert. Ein Mode für Checkbranches. Ein Error Typ, der die Position und eine Nachricht festhält, ebenso wie einen zuständigen ErrorHandler. Pragma hat was mit den go directives zu tun.
\begin{lstlisting}
func Parse(base *PosBase, src io.Reader, errh ErrorHandler, pragh PragmaHandler, mode Mode) (_ *File, first error) {
	defer func() {
		if p := recover(); p != nil {
			if err, ok := p.(Error); ok {
				first = err
				return
			}
			panic(p)
		}
	}()

	var p parser
	p.init(base, src, errh, pragh, mode)
	p.next()
	return p.fileOrNil(), p.first
}
\end{lstlisting}
Im nächsten Schritt wird die Funktion Parse definiert. Diese benutzt die entsprechenden Felder, um Dinge wie den Source Code als IO Stream zu übergeben. Hier wird ein Parser definiert, der nach der Initialisation auf das erste Token geschaltet wird. In der Parser Initialisation wird der oben beschriebene Scanner Initialisiert. Wenn bei der Parse Funktion ein Panic auftritt, z.B indem ein Syntax Error auftritt, wird dieses recovered und der Fehler wird übergeben und das Programm ist zu Ende. Falls es kein Syntax Fehler war sondern ein anderer Panic Fehler, wird weiterhin mit Panic das Programm unterbrochen. Anschließend wird weiterhin das Programm mit Panic unterbrochen.

Ebenso existiert eine Funktion ParseFile, die Parse benutzt und als Source nicht einen Text sondern ein File benutzt.

Mit der Funktion fileOrNil geht es weiter. If trace = true, dann wird die trace Funktion aufgerufen.

\begin{lstlisting}
func (p *parser) fileOrNil() *File {
if trace {
		defer p.trace("file")()
	}

	f := new(File)
	f.pos = p.pos()

	// PackageClause
	f.GoVersion = p.goVersion
	p.top = false
	if !p.got(_Package) {
		p.syntaxError("package statement must be first")
		return nil
	}
	f.Pragma = p.takePragma()
	f.PkgName = p.name()
	p.want(_Semi)

	// don't bother continuing if package clause has errors
	if p.first != nil {
		return nil
	}

	// Accept import declarations anywhere for error tolerance, but complain.
	// { ( ImportDecl | TopLevelDecl ) ";" }
	prev := _Import
	for p.tok != _EOF {
		if p.tok == _Import && prev != _Import {
			p.syntaxError("imports must appear before other declarations")
		}
		prev = p.tok

		switch p.tok {
		case _Import:
			p.next()
			f.DeclList = p.appendGroup(f.DeclList, p.importDecl)

		case _Const:
			p.next()
			f.DeclList = p.appendGroup(f.DeclList, p.constDecl)

		case _Type:
			p.next()
			f.DeclList = p.appendGroup(f.DeclList, p.typeDecl)

		case _Var:
			p.next()
			f.DeclList = p.appendGroup(f.DeclList, p.varDecl)

		case _Func:
			p.next()
			if d := p.funcDeclOrNil(); d != nil {
				f.DeclList = append(f.DeclList, d)
			}

		default:
			if p.tok == _Lbrace && len(f.DeclList) > 0 && isEmptyFuncDecl(f.DeclList[len(f.DeclList)-1]) {
				// opening { of function declaration on next line
				p.syntaxError("unexpected semicolon or newline before {")
			} else {
				p.syntaxError("non-declaration statement outside function body")
			}
			p.advance(_Import, _Const, _Type, _Var, _Func)
			continue
		}

		// Reset p.pragma BEFORE advancing to the next token (consuming ';')
		// since comments before may set pragmas for the next function decl.
		p.clearPragma()

		if p.tok != _EOF && !p.got(_Semi) {
			p.syntaxError("after top level declaration")
			p.advance(_Import, _Const, _Type, _Var, _Func)
		}
	}
	// p.tok == _EOF

	p.clearPragma()
	f.EOF = p.pos()

	return f
}
\end{lstlisting}
Ein neues File wird in der Variable f erstellt. Die Position wird von der aktuellen Parser Position übernommen. Als Nächstes wird die Funktion got(token) benutzt.

\begin{lstlisting}
func (p *parser) got(tok token) bool {
	if p.tok == tok {
		p.next()
		return true
	}
	return false
}
\end{lstlisting}
Diese überprüft, ob das aktuelle Parser Token mit dem übergebenen Token übereinstimmt, gibt true oder false heraus und schaltet auf das nächste Token, wenn es übereinstimmt.

Somit wird überprüft, ob das erste Token, welches vorkommt im File, ein Package Token ist. Dieses muss als erstes Statement auftreten.

\begin{lstlisting}
// takePragma returns the current parsed pragmas
// and clears them from the parser state.
func (p *parser) takePragma() Pragma {
	prag := p.pragma
	p.pragma = nil
	return prag
}
\end{lstlisting}
Als nächstes werden die Pragmas vom Parser genommen, dort gecleart und in dem File gespeichert. Ebenso wird der Package Name umgespeichert. Dann wird die want Funktion mit dem Semi Token aufgerufen.

\begin{lstlisting}
func (p *parser) want(tok token) {
	if !p.got(tok) {
		p.syntaxError("expected " + tokstring(tok))
		p.advance()
	}
}
\end{lstlisting}
Diese überprüft, ob der übergebene Token übereinstimmt. Ist dies nicht der Fall, wird ein Syntax Fehler aufgerufen zusammen mit der Funktion advance. 

\begin{lstlisting}
// advance consumes tokens until it finds a token of the stopset or followlist.
// The stopset is only considered if we are inside a function (p.fnest > 0).
// The followlist is the list of valid tokens that can follow a production;
// if it is empty, exactly one (non-EOF) token is consumed to ensure progress.
func (p *parser) advance(followlist ...token) {
	if trace {
		p.print(fmt.Sprintf("advance %s", followlist))
	}

	// compute follow set
	// (not speed critical, advance is only called in error situations)
	var followset uint64 = 1 << _EOF // don't skip over EOF
	if len(followlist) > 0 {
		if p.fnest > 0 {
			followset |= stopset
		}
		for _, tok := range followlist {
			followset |= 1 << tok
		}
	}

	for !contains(followset, p.tok) {
		if trace {
			p.print("skip " + p.tok.String())
		}
		p.next()
		if len(followlist) == 0 {
			break
		}
	}

	if trace {
		p.print("next " + p.tok.String())
	}
}
\end{lstlisting}
Diese Funktion nimmt Token und schaltet auf das nächste, bis ein Token aus der übergebenen Liste auftaucht oder das Ende des Files. In dem konkreten Beispiel wird die Funktion mit leerem Parameter aufgerufen. Das bedeutet, dass nur am Ende des Files angehalten wird und somit alle Token übersprungen werden. Zusammen mit der Rückgabe eines Syntax Errors bedeutet dies das Ende des Parsers.

Ist das Semi Token vorhanden, wird normal fortgefahren. Dieses Semi Token ist entweder ein Strichpunkt, eine neue Zeile oder das Ende des Files. Somit wird überprüft, ob ein Abstand zwischen dem Package Statement vorhanden ist. Das z.B. Import Statement in die gleiche Zeile wie das Package Statement zu packen, funktioniert somit nicht.

Weiter in der fileOrNil Funktion geht es mit einer For Schleife. Diese läuft bis File Ende und überprüft zuerst ob Import Statements vorhanden sind. Bei Deklaration nach anderen Statements wird ein SyntaxError ausgegeben, der Parser läuft aber weiter. 

Mit Switch Case werden einzelne Token Fälle behandelt. Bei Import, Konstanten, Typ oder Variablen Deklarationen wird die Deklaration in einer jeweiligen Gruppe gesammelt und auf den nächsten Token weitergeschalten. Bei einem Funktionstoken wird zuerst die Funktion funcDeclOrNil aufgerufen und anschließend eine Gruppe gebildet.

\begin{lstlisting}
func (p *parser) funcDeclOrNil() *FuncDecl {
	if trace {
		defer p.trace("funcDecl")()
	}

	f := new(FuncDecl)
	f.pos = p.pos()
	f.Pragma = p.takePragma()

	var context string
	if p.got(_Lparen) {
		context = "method"
		rcvr := p.paramList(nil, nil, _Rparen, false)
		switch len(rcvr) {
		case 0:
			p.error("method has no receiver")
		default:
			p.error("method has multiple receivers")
			fallthrough
		case 1:
			f.Recv = rcvr[0]
		}
	}

	if p.tok == _Name {
		f.Name = p.name()
		f.TParamList, f.Type = p.funcType(context)
	} else {
		f.Name = NewName(p.pos(), "_")
		f.Type = new(FuncType)
		f.Type.pos = p.pos()
		msg := "expected name or ("
		if context != "" {
			msg = "expected name"
		}
		p.syntaxError(msg)
		p.advance(_Lbrace, _Semi)
	}

	if p.tok == _Lbrace {
		f.Body = p.funcBody()
	}

	return f
}
\end{lstlisting}
In dieser Funktion wird überprüft, ob der Funktionsaufbau stimmt. Da das erste Token immer das func Keyword ist, muss dies nicht mehr überprüft werden. Zuerst wird überprüft, ob direkt nach dem func Keyword ein Lparens Token folgt. Dieses stellt eine linke Klammer ( dar. Ist diese vorhanden, handelt es sich um eine Methode und es muss ein Methodenreciever definiert werden. Bei Reciever oder  mehr als eine wird ein Fehler zurückgegeben. Ansonsten wird der Reciever gespeichert. Dies passiert in der Funktion paramList die dementsprechend aufgerufen wird.
\begin{lstlisting}
    
\end{lstlisting}
Als Nächstes muss der Funktionsname folgen. 

Danach könnten TypParameter folgen. Diese werden in [] nach dem Namen definiert und bewirken, dass eine Funktion für einen generische Typ und somit mehrere konkrete Typen definiert werden kann. Dies wird mi

\begin{lstlisting}
func (p *parser) funcType(context string) ([]*Field, *FuncType) {
	if trace {
		defer p.trace("funcType")()
	}

	typ := new(FuncType)
	typ.pos = p.pos()

	var tparamList []*Field
	if p.got(_Lbrack) {
		if context != "" {
			// accept but complain
			p.syntaxErrorAt(typ.pos, context+" must have no type parameters")
		}
		if p.tok == _Rbrack {
			p.syntaxError("empty type parameter list")
			p.next()
		} else {
			tparamList = p.paramList(nil, nil, _Rbrack, true)
		}
	}

	p.want(_Lparen)
	typ.ParamList = p.paramList(nil, nil, _Rparen, false)
	typ.ResultList = p.funcResult()

	return tparamList, typ
}
\end{lstlisting}
Es muss ein SyntaxFehler bei einer leeren TypParameter Liste gegeben werden. Nach den TypParamtern folgen die Funktionsparameter in runden Klammern().  Als Letztes muss der Rückgabetyp folgen. Dieser kann in runden Klammern stehen. Mit der Funktion funcResult und typeOrNil wird überprüft, um welchen Typ es sich handelt. Dies wird statt dem type\_ Token verwendet, da Rückgabewert weggelassen werden kann. 

\begin{lstlisting}
func (p *parser) funcResult() []*Field {
	if trace {
		defer p.trace("funcResult")()
	}

	if p.got(_Lparen) {
		return p.paramList(nil, nil, _Rparen, false)
	}

	pos := p.pos()
	if typ := p.typeOrNil(); typ != nil {
		f := new(Field)
		f.pos = pos
		f.Type = typ
		return []*Field{f}
	}

	return nil
}

\end{lstlisting}

\subsection{Type checking}
Benutzt das types2 Package.
\subsection{Intermediate Representation(IR) construction (“noding”)}
Der darauf folgende Zwischencode benutzt eine eigene AST Definition und Repräsentation von Go Typen. Umwandlung der Repräsentationen, die  syntax und types2 genannt werden, müssen zu den Repräsentationen IR and types erfolgen. Das wird als “noding" bezeichnet.
Noding benutzt einen Prozess names Unified IR, der eine Repräsentation der nodes erstellt. Es wird die typgeprüfte Version des vorherigen Schrittes benutzt. Unified IR wird auch für import/export von packages and inlining benötigt.
\subsection{Zwischencode mit Optimierung}
dead code elimination, (early) devirtualization, function call inlining, und escape analysis.
Die early dead code elimination ist integriert in die unified IR writer Phase.
\subsection{Walk}
Komplexe Statements werden vereinfacht, ohne die Reihenfolge der Auswertung zu verändern. Höhere Go Konstrukte werden in ihre primitiven Konstrukte  umgewandelt. Ein Beispiel ist die Umwandlung von switch statements in binary search.
\subsection{Generic Static Single Assignment(SSA)}
Vereinfacht Optimierung und macht es einfacher daraufhin Maschinencode zu erzeugen.
\subsection{Erzeugung Machinencode}
Eine letzte code Optimierung wird durchgeführt vor der Erzeugung des Machinencodes.
\subsection{Export}
Export Data wird in einem File gespeichert. Dieses beinhaltet alle nötigen Informationen des gerade kompilierten Package, das verwendet werden kann, wenn das es von einem anderen Package importiert werden soll.
\subsection{CGO Compiler und Kompatibilität mit C} 
CGO ist nicht standardmäßig in Go aktiviert, da es Laufzeit kostet. Es kann aktiviert werden, in dem der Wert der Umgebungsvariable CGO\_ENABLED auf 1 geändert wird. Dazu gibt es den Konsolenbefehl go env -w "CGO\_ENABLED=1".
Daraufhin wird C Code wie z.B das \#define File.h Statement benötigt .Dieses muss auskommentiert sein mit //. Darunter muss ein import "C" Statement stehen. Alle Kommentare darüber werden als C Code gewertet. Ein C Compiler muss installiert sein um CGO benutzten zu können. Momentan wird nur der Compiler Gcc unterstützt.


\section{Namen und Bindungen}
\subsection{Naming Konditionen/Best practice}
\subsection{Gültigkeitsbereiche(Scopes)}
\subsubsection{Block Scope}
nächsthöherer Block entscheidend, z.B Funktion
Shadowing: Variable kann in einem inneren Block neu definiert werden. Diese wird benutzt in dem Scope, in der diese definiert wurde.
Definierte Variablen sind nur innerhalb dieses Blocks verfügbar oder in weiteren inneren Blöcken innerhalb des Original Blocks.
\subsubsection{Package Scope}
Wird eine Variable außerhalb eines spezifischen Blocks definiert, ist die Variable innerhalb des ganzen Packages verfügbar.
\subsubsection{Global Scope}
Zusätzlich zu den Konditionen des Package Scopes muss die Variable groß geschrieben werden. Dann kann jedes Package, welches das momentan benutzte Package importiert, auf die Variable zugreifen. Bei Kleinschreiben der globalen Variable wird ein Compiler Fehler ausgegeben.
\subsubsection{Lifetimes}
Die Lifetime ist bei Blöcken genauso lange wie die Ausführung des jeweiligen Blockes dauert. 
Package und globale Variablen sind das ganze Programm lang vorhanden und deshalb auf dem Heap gespeichert.
\subsection{Kontrollstrukturen}
Keine While Loop, keine Do Loop
If Statement, For Loop, Switch Statement, goto
\subsection{Statische vs Dynamische Bindung, heißt die Namen sind meist statisch gebunden und Werte von Variablen meist dynamisch}
Dynamisch gebunden wird z.B für Polymorphismus bei Objekten genutzt. Es wird automatisch die richtige Funktion während der Laufzeit ausgesucht und aufgerufen, je nach dem, um welchen Objekttyp es sich gerade handelt. 
In Go wird Polymorphismus aber nur durch Interfaces benutzt, da Klassen nicht existieren. Mehrere Typen können dasselbe Interface implementieren. Somit sollte alles statisch gebunden(während Kompilierzeit bereits bekannt) sein, und nur Interfaces teilweise dynamisch.
\subsection{Closures}

\section{Speicher}
\subsection{Garbage Collector}
\subsection{Möglichkeit zur Selbstverwaltung}

\section{Werte und Typen}
%\cite{alan_a_a_donovan_go_2015} 
\subsection{Basic Types}
\subsubsection{Integer}
int8 int16 int32(rune) and int64\\uint8(byte) uint16 uint32 and uint64\\int und uint, entweder 32 oder 64 bits, ausgesucht vom compiler\\uintptr, undefiniert aber groß genug für alle Bits eines pointer values
\subsubsection{Floating Point}
float32 und float64
\subsubsection{Complex Numbers}
complex64 und complex128
\subsubsection{Boolean}
bool
\subsubsection{Strings}
string, sequence of bytes
\subsubsection{Constants}
underlying type is basic type, value known at compile time

\subsection{Aggregate types}
Kombinieren mehrerer Werte zu komplexeren Strukturen.
Es gibt keine Vereerbung in GO. Es existieren keine Klassen. Für Wiederverwendung können structs benutzt werden und durch die Interfaces kann Komposition implementiert werden. Structs können innerhalb anderer Structs definiert werden.
\subsubsection{Arrays}
fixed length, one type\\
Arrays als Parameter für eine Funktion kopiert standardmäßig das Array und benutzt diese. Änderung am Original können erlaubt werden wenn der Pointer auf das Array übergeben wird.
\subsubsection{Structs}
Kollektion von Variablen

\subsection{Reference types}
Referenzieren indirekt, damit alle Operationen für alle Kopien gelten, die diese Referenz benutzen. Alle Datenstrukturen sind Referenzen. Wenn z.B eine Map kopiert wird, wird die Referenz dahinter kopiert und diese zeigt auf dieselbe Map.
\subsubsection{Pointers}
\subsubsection{Slices}
dynamische Länge, ein Typ
\\Slice hat ein Array unter sich. Slice besteht aus Pointer zum ersten erreichbaren Array Element(nicht zwingend erstes Array Element), Länge also Anzahl der Slice Elemente und der Kapazität
\\2 Slices können das gleiche Array unter sich haben
\\Da Slice ein Pointer auf das Array hat, muss nur der Slice an eine Funktion übergeben werden und das Array darunter kann verändert werden.
\\Kapazität sagt im Prinzip aus, wie groß momentan das unterliegende Array ist
\\wenn Wert hinzugefügt werden soll, muss bei Platzproblemen ein neues unterliegendes Array erzeugt werden und alle Werte dorthin kopiert werden. Normalerweise ist dieses Array nun doppelt so groß wie zuvor. Wenn 2 Slices vorher dasselbe Array benutzt haben, ist dies nun nicht mehr der Fall.
\subsubsection{Maps}
ungeordnete Kollektion von Key-Value Paaren
\subsubsection{Functions}
Die Syntax von Funktionen lautet: func(Keyword) Funktionsname(Parameter) Rückgabewert.
Defered Functions: Eine Funktion, die ein defer statement beinhaltet wird zur deferred Function. Dieses Statement wird ausgeführt, nachdem die defered Function vollständig zuende gebracht wurde.
\subsubsection{Methods}
Methoden müssen einem Typen zugeordnet werden. Die Syntax lautet  func(Keyword) (reciever type) Funktionsname(Parameter) Rückgabewert. Der Typ ist z.B ein vorher selbst definiertes struct. Mit Methoden können diesen Typen Funktionalität gegeben werden.
\subsubsection{Channels}
Channel: benutzt zum Senden von Variablen Werten zwischen Goroutines. Haben einen spezifischen Typ.

\subsection{Interface types}
Gereralisiert und abstrahiert Teile des Codes. Erlaubt ähnliche Funktionen zusammenzubündeln und vermeidet doppelten Code. In GO müssen die Konditionen eines Interfaces nur implizit erfüllt werden müssen. Ein Typ implementiert das Interface durch Implementierung der Methode. Es müssen nur die definierten erwarteten Methoden vorhanden sein. Höhere Stellung in Go als in anderen Sprachen da Veerbung mit Klassen nicht existiert.
\subsection{Typprüfung}
\subsection{Typkonversion}


\section{Concurrency}
Mehrere Aufgaben werden zur selben Zeit ausgeführt. Das heißt, dass mehrere Aufgaben in einer Warteschlange sind und diese so schnell wie möglich abgearbeitet werden soll, indem auch hin und her gewechselt werden kann. 
\subsection{Goroutines}
ähnliche Funktionsweise wie Thread

\section{Generics}

\section{Errorhandling and Testing}
\subsection{Möglichkeiten zur Fehlerausgabe}
Ein Error Interface kann implementiert werden.
\subsection{Panic}
Run time Fehler, der das Programm stoppt. Kann manuell gerufen werden und wird benutzt für Fehler, die nur schwer durch das Error Handeling abzudecken sind. Wird automatisch bei z.B Out of bounds array Zugriffen aufgerufen.
\subsection{Recover}
Wird nur bei deferred Functions benutzt. Panic kann abgefangen werden und das Programm kann daraufhin ohne Run time Fehler zu Ende laufen.

\section{Reflection}
Erlaubt Manipulation von Werten zur Runtime oder Inspektion von Variablen zur Runtime. Use case ist z.B wenn viele spezifische Typen existieren können. Hier müsste man für jeden custom typ ein Fall aufgezogen werden. Mit Reflection kann man aber unterliegende Typen und Werte dieser herausfinden, um die unzähligen möglichen Custom types auf die Basic Types wie int, String etc. zu reduzieren.
Reflection muss oft nicht selbst benutzt werden, wird aber in einigen Packages benutzt.

\section{Fehlende Features}

\section{Bücher}
Let's go Alex Edwards\\ 
Let's go further Alex Edwards\\
