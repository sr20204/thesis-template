\chapter{Aspekte von Go}\label{ch:method}

\section{Compiler und Dinge wie Scanner und Parser, Semantische Analyse}
\subsection{Scanner short}
In der Syntax.go Datei wird die Funktion Parse definiert. Diese Definiert einen Parser und ruft dann dessen Initialisierungsfunktion auf. Danach wird der Parser auf das nächste Token geschalten. 
Der Parser ruft die Scanner init- Funktion auf. Der Scanner selbst ist definiert in der scanner.go Datei, der Parser hingegen in der Parser.Go Datei. Alle drei Dateien sind in dem Ordner src/cmd/compile/internal/syntax. 
Der Scanner besitzt einige Felder zum identifizieren von Token. 
Source wird mit dem IO Stream des zu scannenden Textes übergeben.
Die mode flags kontrollieren welche Kommentare als Fehler geflaged werden. 
Bei nicht Setzung werden alle Kommentare ignoriert. Bei Setzen auf 1 werden alle Kommentare an den Error Handler übergeben, bei Setzen auf 2 nur die directives. Directives in Go sind spezifische Compiler Instruktionen, die ebenfalls mit // beginnen. Diese können überallhin platziert werden. Die Syntax ist //go:directive. Pragmas und Directives sind Synonyme. Benutzen von diesen ist generell eher unerwünscht. Diese sind frühere Implementierungen und sollten eher durch andere Packages oder Varianten ersetzt werden.
NlSemi bestimmt, ob \escape{n} und das Ende des Files zu ; übersetzt werden. Dies hat den Vorteil, dass manuell keine Strichpunkte mehr gesetzt werden müssen, da der Kompiler dies automatisch tut in jeder Neuen Zeile. Hier kann es aber zu Einschränkungen kommen. Geschweifte Klammern nach Kontrollstrukturen(if,switch) können nicht in die nächste Zeile gesetzt werden, da sonst ein Strichpunkt vom Compiler dahinter gesetzt werden würde. Eine einzelne geschweifte Klammer ist ein ungültiges Statement. Somit muss die geschweifte Klammer immer in der gleichen Zeile wie die Kontrollstruktur sein, da diese dort erwartet wird. 
Line und col ist die aktuelle Position des gelesenen Characters. Blank??????. Tok ist das resultierende Token. Lit wird benutzt, um zwischenzuspeichern, falls ein Name, ein Literal oder eine der drei Semicolon Fälle auftreten. Bad wird benutzt um zu kennzeichen, dass ein Syntax Error aufgetreten ist. Kind beschreibt die Art des Literals, falls dieses auftritt. Op und Prec speichern Werte, falls ein Operator, Star, AssignOp oder IncOp Token auftritt.
Eine Keyword map wird benutzt um zu testen, ob ein es sich um ein Keyword Token handelt.

Die Funktion next liest den nächsten Token. Es werden alle whitespace Character übersprungen. Der Scanner wird auf den Start des tatsächlichen Tokens eingestellt. Ist das Token gefunden, wird sich der erste Character angeschaut. 
Es wird festgelegt, dass ein Token nicht mit einer Zahl beginnen darf. Buchstaben oder \_(underscore) sind dort in Ordnung. Wenn der Character größer als utf8.RuneSelf(Ist das einfach die größe einer StandarRune???) ist, dann wird davon ausgegangen, dass der Character außerhalb der gültigen Zeichen liegt. In beiden Fällen wird ein Fehler ausgegeben. Werden diese Regeln eingehalten, dann kann sich der nächste Character angeschaut werden.
Solange auf den ersten Character Buchstaben und Zahlen folgen, wird der Character übersprungen da es sich um einen String oder um eine Zahl handelt.
Wenn das Wort oder die Zahl zu Ende ist, wird geprüft ob es mehr als einen Character hat(Warum das??,warum mehr als einen Character benötigt). Ist dies der Fall, hat man ein Keyword gefunden und das Token wird dementsprechend gesetzt.
Weiterhin folgen einige speziellere Fälle, die mit einem Switch Case Statement durchlaufen werden. Diese lassen sich weiter aufteilen in die Kommentare und Pragmas, Operatoren Zeichen und zu Letzt alle weiteren Zeichen, die benutzt werden.  

Ist mode so gesetzt, dass Kommentare Fehler zurückgeben, werden Directives berücksichtigt. Zusätzlich muss skipLine aufgerufen werden. Diese Funktion stellt sicher, dass der Character \\n übersprungen wird. Dieser wird benötigt, um die Logik für nlsemi umzusetzen. Wenn mode auf nur Directives gesetzt ist, wird überprüft ob es sich um eine handelt. Diese müsste mit //go: oder mit \\l (für \\line:) starten. Ist dies nicht der Fall, wird die Funktion stop aufgerufen. Wird trotzdem eine Directive erkannt, wird diese als Fehler zurückgegeben.\\
Mehrzeilige Kommentare werden genauso behandelt wie eine neue Zeile. Ein Unterschied ist in der Full Comment Funktion.(Was ist diese???)
Die line Directive muss speziell erkannt und behandelt werden.
Ist kein // vorhanden sondern nur ein einzelner /, muss es sich um einen Operator handeln und dementsprechend wird dorthin gesprungen. Neue Zeilen (/n werden direkt als Neue Zeilen Token erkannt.

Zahlen an der ersten Character stelle wurde bereits behandelt. Jede weitere Zahl ist somit die zweite Ziffer. Davor muss entschieden werden, ob es sich um eine Kommazahl handelt.
Folgt direkt die zweite Zahl, ist es keine Kommazahl. In dieser wird standardmäßig die Basis als Dezimalzahl behandelt. Dies muss geändert werden, wenn auf den Character 0 ein weitere Character folgt, der keine Zahl ist. Für das Hexadezimal System ist dies x, für das Oktalsystem o und für das Binärsystem b(z.B 0x 0o 0b oder????). Digsep sagt aus ob ein Seperator vorhanden ist. 
Der Seperator muss ebenfalls an die Basis angepasst werden. Je nach Fall muss bei vorkommen eines Seperators ein Fehler zurückgegeben werden.

Um Exponenten auszudrücken werden die Character e und p benutzt. Wenn der Character e vorhanden ist, muss die Zahl(Mantisse) vor dem Exponent eine Dezimalzahl sein. Wenn p benutzt wird, muss es eine Hexadezimalzahl sein.
Bei + oder - wird der Character übersprungen(warum???). Zusätzlich wird gefordert, dass eine Hexadezimalzahl einen Exponenten mit dem Character p startet. Der Character i kann ebenfalls noch vorkommen und in dem Fall gesetzt. 

Wenn eine Ziffer ungültig war, wird dieser Fall am Schluss geprüft und als Fehler ausgegeben. Ebenso wird der erste ungültige Seperator ausgegeben falls vorhanden.

Klammern aller Art, das Komma und der Strichpunkt werden direkt als Token erkannt.
Der Doppelpunkt wird als Dopplepunkt erkannt, außer wenn darauf ein Istgleich Zeichen folgt. Dies ist der Define Operator, mit welchem Variablen definiert werden können.

Der Punkt wird als Kommapunkt gewertet, wenn darauf eine Dezimalzahl folgt. Wenn zwei weitere Punkte folgen wird es als ... Operator erkannt. Dieser wird die Definition einer variablen Anzahl von Parametern benutzt. Ansonsten wird es als Punkt gewertet, der z.B bei Zugriff auf Typ Methoden eingesetzt wird.\\
\\ Ein weitere größere Unterteilung bilden die Operatoren. Beginnend mit den Standardoperatoren + und -.
Wenn nur ein einzelnes Zeichen existiert, wird zum Label AssignOp gesprungen.Dieses prüft, ob es sich um den AssignOpertor handelt. Wenn nicht wird einfach nur der Token auf Operator gesetzt.\\
Kommen zwei + oder zwei - vor, dann wird dieses als Increment oder als Decrement Operator gewertet, der jeweils +1 oder -1 auf eine Variable rechnet.Wenn auf * oder / ein = folgt, dann wird dieses als Assign Operator gewertet. Für * wird extra das Token auf \_Star gesetzt. Für / wird der Assign Operator bei AssignOp gesetzt.
Für die Operatoren \%, \^ und \~ werden nur die jeweiligen Operator Token gesetzt. < und > haben decken folgende Operatoren Fälle ab: >= und <=, >> und <<, zuletzt <-. Für | und \& werden sowohl die einzelnen Logik Operatoren als auch die doppelten \&\& und || zugewiesen. Zusätzlich existiert nicht der AndNot Operator \&\^.Zuletzt gibt es noch den Equal Operator ==, der im Fall eines einzelnen = ein Assign Operator ist. Für ! existiert der Not Operator ! und der Not Equal Operator !=. \\
\\ Zuletzt werden noch die String Methoden " ' und ` mit jeweils eigenen Methoden erkannt.
Für den Standard String "" werden einige Fälle definiert. Wenn direkt der zweite " folgt dann ist es der leere String und es kann abgebrochen werden. Falls ein Backslash in dem String alleine vorkommt, ist dies ein Escape Zeichen und die Funktion wird aufgerufen. In diesem Fall gibt diese aber nur true zurück. 
Existiert ein Whitespace in dem String wird ein Fehler ausgeworfen, dass eine neue Zeile im String enthalten ist. Falls kein zweites " mehr folgt, wird der Fehler ausgeworfen dass der String nicht terminiert wurde. Für den raw String existiert der leere String `` oder der nicht terminierte String.
Für die rune Funktion gibt es ähnliche Fälle. Die leere Rune ist nicht gültig. Somit wird dies geprüft genauso weil der Fall wenn mehr als ein Character in einer Rune enthalten ist. Weiterhin gibt es den Escape mit Backslash, die Neue Zeile mit Whitespace und den Fall dass das Rune literal nicht terminiert wurde.

Bevor der Parser übernimmt, wird in dem parser.go File der Scanner initialisiert. Hierzu wird als Source der Io Reader genutzt, der dem Parser übergeben wurde. Als nächstes müssen Error und Directive Handler definiert werden. Für den Error Handler reicht eine einfacher Prüfung, ob eine Nachricht gesetzt wurde. Dann kann ein Fehler mit aktueller Position ausgegeben werden. Für den Directive Handler wird zuerst nach line( //line) Directives geprüft. Dazu muss die Directive am Anfang der Linie starten. Somit muss die aktuelle Spalte der Spaltenbasis gleichen oder die msg enthalt einen Stern an zweiter Positon, um die Directive /*line*/ abzudecken, die überall in der Zeile vorkommen kann. Die Position nach dem Ende der Directive wird gefunden und gespeichert. 
Danach werden die directives übergeben.Ab hier übernimmt nun der Parser.

\subsection{Parser(Syntactic and Semantic Analysis)}
\subsection{Parser allgemein}
Im nächsten Schritt wird die Funktion Parse definiert. Diese benutzt die entsprechenden Felder, um Dinge wie den Source Code als IO Stream zu übergeben. Hier wird ein Parser definiert, der nach der Initialisation auf das erste Token geschaltet wird.
In der Parser Initialisation wird der oben beschriebene Scanner Initialisiert. Wenn bei der Parse Funktion ein Panic auftritt, z.B indem ein Syntax Error auftritt, wird dieses recovered und der Fehler wird übergeben und das Programm ist zu Ende. Falls es kein Syntax Fehler war sondern ein anderer Panic Fehler, wird weiterhin mit Panic das Programm unterbrochen. Anschließend wird weiterhin das Programm mit Panic unterbrochen.

Es wird überprüft, ob das erste Token, welches vorkommt im File, ein Package Token ist. Dieses muss als erstes Statement auftreten.
Ist als Nächstes ein Semi Token vorhanden, wird normal fortgefahren. Dieses Semi Token ist entweder ein Strichpunkt, eine neue Zeile oder das Ende des Files. Somit wird überprüft, ob ein Abstand zwischen dem Package Statement vorhanden ist. Das z.B. Import Statement in die gleiche Zeile wie das Package Statement zu packen, funktioniert somit nicht.
Es wird überprüft in einer for Schleife, um welche Token es sich handelt. Kommt ein Import Token vor(Import Statement), wird überprüft, ob vorher ein Import Token vorgekommen ist. Dies muss passieren, da vor den Import Statements keine anderen Deklarationen stehen können. Für Import Const Type Var werden jeweils AppendGroup aufgerufen, falls diese vorkommen. Für das Funktionstoken gibt es eine extra Funktion. 

In dieser Funktion wird überprüft, ob der Funktionsaufbau stimmt. Da das erste Token immer das func Keyword ist, muss dies nicht mehr überprüft werden. Zuerst wird überprüft, ob direkt nach dem func Keyword ein Lparens Token folgt. Dieses stellt eine linke Klammer ( dar. Ist diese vorhanden, handelt es sich um eine Methode und es muss ein Methodenreciever definiert werden. Bei fehlendem Reciever oder mehr als einer wird ein Fehler zurückgegeben. Ansonsten wird der Reciever gespeichert. Dies passiert in der Funktion paramList die dementsprechend aufgerufen wird.
Als Nächstes muss der Funktionsname folgen. 

Danach könnten TypParameter folgen. Diese werden in [] nach dem Namen definiert und bewirken, dass eine Funktion für einen generische Typ und somit mehrere konkrete Typen definiert werden können. Dieser darf nicht leer sein. Nach dem TypParameter folgen die richtigen Parameter. Nach diesem der Rückgabewert der Funktion. Der Rückgabewert kann ebenfalls in Klammern sein. Dort wird jeweils überprüft, ob diese wieder richtig geschlossen werden. Mit der Funktion funcResult und typeOrNil wird überprüft, um welchen Typ es sich handelt. Dies wird statt dem type\_ Token verwendet, da Rückgabewert weggelassen werden kann. 

Dort gibt es mehrere Möglichkeiten. Wenn direkt die linke Klammer folgt und kein anderes Token, gibt es keinen Rückgabewert und die Klammer muss nur noch geschlossen werden. Kommt ein Stern(*) vor, handelt es sich um den PointerType. Mit einem Pfeil( ->) um den Reciever Channel Type. Mit dem Func Token handelt es sich um einen FunktionsTypen. Mit der eckicken Klammer könnte es sich um einen SliceTyp oder um den ArrayTyp handeln. Ebenso kann der Channel, Map, Interface und Name Type vorkommen. 

Danach folgt der Funktionsbody, falls vorhanden. In dieser werden die Branches mit checkBranches überprüft. Diese ist in der branches.go Datei. 

\subsection{Type checking}
Benutzt das types2 Package.
\subsection{Intermediate Representation(IR) construction (“noding”)}
Der darauf folgende Zwischencode benutzt eine eigene AST Definition und Repräsentation von Go Typen. Umwandlung der Repräsentationen, die  syntax und types2 genannt werden, müssen zu den Repräsentationen IR and types erfolgen. Das wird als “noding" bezeichnet.
Noding benutzt einen Prozess names Unified IR, der eine Repräsentation der nodes erstellt. Es wird die typgeprüfte Version des vorherigen Schrittes benutzt. Unified IR wird auch für import/export von packages and inlining benötigt.
\subsection{Zwischencode mit Optimierung}
dead code elimination, (early) devirtualization, function call inlining, und escape analysis.
Die early dead code elimination ist integriert in die unified IR writer Phase.
\subsection{Walk}
Komplexe Statements werden vereinfacht, ohne die Reihenfolge der Auswertung zu verändern. Höhere Go Konstrukte werden in ihre primitiven Konstrukte  umgewandelt. Ein Beispiel ist die Umwandlung von switch statements in binary search.
\subsection{Generic Static Single Assignment(SSA)}
Vereinfacht Optimierung und macht es einfacher daraufhin Maschinencode zu erzeugen.
\subsection{Erzeugung Machinencode}
Eine letzte code Optimierung wird durchgeführt vor der Erzeugung des Machinencodes.
\subsection{Export}
Export Data wird in einem File gespeichert. Dieses beinhaltet alle nötigen Informationen des gerade kompilierten Package, das verwendet werden kann, wenn das es von einem anderen Package importiert werden soll.
\subsection{CGO Compiler und Kompatibilität mit C} 
CGO ist nicht standardmäßig in Go aktiviert, da es Laufzeit kostet. Es kann aktiviert werden, in dem der Wert der Umgebungsvariable CGO\_ENABLED auf 1 geändert wird. Dazu gibt es den Konsolenbefehl go env -w "CGO\_ENABLED=1".
Daraufhin wird C Code wie z.B das \#define File.h Statement benötigt .Dieses muss auskommentiert sein mit //. Darunter muss ein import "C" Statement stehen. Alle Kommentare darüber werden als C Code gewertet. Ein C Compiler muss installiert sein um CGO benutzten zu können. Momentan wird nur der Compiler Gcc unterstützt.


\section{Namen und Bindungen}
\subsection{Naming Konditionen/Best practice}
\subsection{Gültigkeitsbereiche(Scopes)}
\subsubsection{Block Scope}
nächsthöherer Block entscheidend, z.B Funktion
Shadowing: Variable kann in einem inneren Block neu definiert werden. Diese wird benutzt in dem Scope, in der diese definiert wurde.
Definierte Variablen sind nur innerhalb dieses Blocks verfügbar oder in weiteren inneren Blöcken innerhalb des Original Blocks.
\subsubsection{Package Scope}
Wird eine Variable außerhalb eines spezifischen Blocks definiert, ist die Variable innerhalb des ganzen Packages verfügbar.
\subsubsection{Global Scope}
Zusätzlich zu den Konditionen des Package Scopes muss die Variable groß geschrieben werden. Dann kann jedes Package, welches das momentan benutzte Package importiert, auf die Variable zugreifen. Bei Kleinschreiben der globalen Variable wird ein Compiler Fehler ausgegeben.
\subsubsection{Lifetimes}
Die Lifetime ist bei Blöcken genauso lange wie die Ausführung des jeweiligen Blockes dauert. 
Package und globale Variablen sind das ganze Programm lang vorhanden und deshalb auf dem Heap gespeichert.
\subsection{Kontrollstrukturen}
Keine While Loop, keine Do Loop
If Statement, For Loop, Switch Statement, goto
\subsection{Statische vs Dynamische Bindung, heißt die Namen sind meist statisch gebunden und Werte von Variablen meist dynamisch}
Dynamisch gebunden wird z.B für Polymorphismus bei Objekten genutzt. Es wird automatisch die richtige Funktion während der Laufzeit ausgesucht und aufgerufen, je nach dem, um welchen Objekttyp es sich gerade handelt. 
In Go wird Polymorphismus aber nur durch Interfaces benutzt, da Klassen nicht existieren. Mehrere Typen können dasselbe Interface implementieren. Somit sollte alles statisch gebunden(während Kompilierzeit bereits bekannt) sein, und nur Interfaces teilweise dynamisch.
\subsection{Closures}

\section{Speicher}
\subsection{Garbage Collector}
\subsection{Möglichkeit zur Selbstverwaltung}

\section{Werte und Typen}
%\cite{alan_a_a_donovan_go_2015} 
\subsection{Basic Types}
\subsubsection{Integer}
int8 int16 int32(rune) and int64\\uint8(byte) uint16 uint32 and uint64\\int und uint, entweder 32 oder 64 bits, ausgesucht vom compiler\\uintptr, undefiniert aber groß genug für alle Bits eines pointer values
\subsubsection{Floating Point}
float32 und float64
\subsubsection{Complex Numbers}
complex64 und complex128
\subsubsection{Boolean}
bool
\subsubsection{Strings}
string, sequence of bytes
\subsubsection{Constants}
underlying type is basic type, value known at compile time

\subsection{Aggregate types}
Kombinieren mehrerer Werte zu komplexeren Strukturen.
Es gibt keine Vereerbung in GO. Es existieren keine Klassen. Für Wiederverwendung können structs benutzt werden und durch die Interfaces kann Komposition implementiert werden. Structs können innerhalb anderer Structs definiert werden.
\subsubsection{Arrays}
fixed length, one type\\
Arrays als Parameter für eine Funktion kopiert standardmäßig das Array und benutzt diese. Änderung am Original können erlaubt werden wenn der Pointer auf das Array übergeben wird.
\subsubsection{Structs}
Kollektion von Variablen

\subsection{Reference types}
Referenzieren indirekt, damit alle Operationen für alle Kopien gelten, die diese Referenz benutzen. Alle Datenstrukturen sind Referenzen. Wenn z.B eine Map kopiert wird, wird die Referenz dahinter kopiert und diese zeigt auf dieselbe Map.
\subsubsection{Pointers}
\subsubsection{Slices}
dynamische Länge, ein Typ
\\Slice hat ein Array unter sich. Slice besteht aus Pointer zum ersten erreichbaren Array Element(nicht zwingend erstes Array Element), Länge also Anzahl der Slice Elemente und der Kapazität
\\2 Slices können das gleiche Array unter sich haben
\\Da Slice ein Pointer auf das Array hat, muss nur der Slice an eine Funktion übergeben werden und das Array darunter kann verändert werden.
\\Kapazität sagt im Prinzip aus, wie groß momentan das unterliegende Array ist
\\wenn Wert hinzugefügt werden soll, muss bei Platzproblemen ein neues unterliegendes Array erzeugt werden und alle Werte dorthin kopiert werden. Normalerweise ist dieses Array nun doppelt so groß wie zuvor. Wenn 2 Slices vorher dasselbe Array benutzt haben, ist dies nun nicht mehr der Fall.
\subsubsection{Maps}
ungeordnete Kollektion von Key-Value Paaren
\subsubsection{Functions}
Die Syntax von Funktionen lautet: func(Keyword) Funktionsname(Parameter) Rückgabewert.
Defered Functions: Eine Funktion, die ein defer statement beinhaltet wird zur deferred Function. Dieses Statement wird ausgeführt, nachdem die defered Function vollständig zuende gebracht wurde.
\subsubsection{Methods}
Methoden müssen einem Typen zugeordnet werden. Die Syntax lautet  func(Keyword) (reciever type) Funktionsname(Parameter) Rückgabewert. Der Typ ist z.B ein vorher selbst definiertes struct. Mit Methoden können diesen Typen Funktionalität gegeben werden.
\subsubsection{Channels}
Channel: benutzt zum Senden von Variablen Werten zwischen Goroutines. Haben einen spezifischen Typ.

\subsection{Interface types}
Gereralisiert und abstrahiert Teile des Codes. Erlaubt ähnliche Funktionen zusammenzubündeln und vermeidet doppelten Code. In GO müssen die Konditionen eines Interfaces nur implizit erfüllt werden müssen. Ein Typ implementiert das Interface durch Implementierung der Methode. Es müssen nur die definierten erwarteten Methoden vorhanden sein. Höhere Stellung in Go als in anderen Sprachen da Veerbung mit Klassen nicht existiert.
\subsection{Typprüfung}
\subsection{Typkonversion}


\section{Concurrency}
Mehrere Aufgaben werden zur selben Zeit ausgeführt. Das heißt, dass mehrere Aufgaben in einer Warteschlange sind und diese so schnell wie möglich abgearbeitet werden soll, indem auch hin und her gewechselt werden kann. 
\subsection{Goroutines}
ähnliche Funktionsweise wie Thread

\section{Generics}

\section{Errorhandling and Testing}
Error Handling in Go: A Comparative Analysis IEEE Software Journal
gibt keine Exceptions sondern konkrete Werte sollen genauere Fehlermeldungen produzieren
\subsection{Möglichkeiten zur Fehlerausgabe}
Ein Error Interface kann implementiert werden.
\subsection{Panic}
Run time Fehler, der das Programm stoppt. Kann manuell gerufen werden und wird benutzt für Fehler, die nur schwer durch das Error Handeling abzudecken sind. Wird automatisch bei z.B Out of bounds array Zugriffen aufgerufen.
\subsection{Recover}
Wird nur bei deferred Functions benutzt. Panic kann abgefangen werden und das Programm kann daraufhin ohne Run time Fehler zu Ende laufen.

\section{Reflection}
Erlaubt Manipulation von Werten zur Runtime oder Inspektion von Variablen zur Runtime. Use case ist z.B wenn viele spezifische Typen existieren können. Hier müsste man für jeden custom typ ein Fall aufgezogen werden. Mit Reflection kann man aber unterliegende Typen und Werte dieser herausfinden, um die unzähligen möglichen Custom types auf die Basic Types wie int, String etc. zu reduzieren.
Reflection muss oft nicht selbst benutzt werden, wird aber in einigen Packages benutzt.

\section{Fehlende Features}

\section{Bücher}
Let's go Alex Edwards\\ 
Let's go further Alex Edwards\\
