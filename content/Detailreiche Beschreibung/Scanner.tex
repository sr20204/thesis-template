\subsection{Mit allem}
In der Syntax.go Datei wird die Funktion Parse definiert. Diese Definiert einen Parser und ruft dann dessen Initialisierungsfunktion auf. Danach wird der Parser auf das nächste Token geschalten. 
Der Parser ruft die Scanner init- Funktion auf. Der Scanner selbst ist definiert in der scanner.go Datei, der Parser hingegen in der Parser.Go Datei. Alle drei Dateien sind in dem Ordner src/cmd/compile/internal/syntax. 
\cite{donovan_go_2016}
\begin{lstlisting}
// The mode flags below control which comments are reported
// by calling the error handler. If no flag is set, comments
// are ignored.
const (
	comments   uint = 1 << iota // call handler for all comments
	directives                  // call handler for directives only
)

type scanner struct {
	source
	mode   uint
	nlsemi bool // if set '\n' and EOF translate to ';'

	// current token, valid after calling next()
	line, col uint
	blank     bool // line is blank up to col
	tok       token
	lit       string   // valid if tok is _Name, _Literal, or _Semi ("semicolon", "newline", or "EOF"); may be malformed if bad is true
	bad       bool     // valid if tok is _Literal, true if a syntax error occurred, lit may be malformed
	kind      LitKind  // valid if tok is _Literal
	op        Operator // valid if tok is _Operator, _Star, _AssignOp, or _IncOp
	prec      int      // valid if tok is _Operator, _Star, _AssignOp, or _IncOp
}
\end{lstlisting}
Der Scanner besitzt einige Felder zum identifizieren von Token. 
Source wird mit dem IO Stream des zu scannenden Textes übergeben.
Die mode flags kontrollieren welche Kommentare als Fehler geflaged werden. 
Bei nicht Setzung werden alle Kommentare ignoriert. Bei Setzen auf 1 werden alle Kommentare an den Error Handler übergeben, bei Setzen auf 2 nur die directives. Directives in Go sind spezifische Compiler Instruktionen, die ebenfalls mit // beginnen. Diese können überallhin platziert werden. Die Syntax ist //go:directive. Pragmas und Directives sind Synonyme. Benutzen von diesen ist generell eher unerwünscht. Diese sind frühere Implementierungen und sollten eher durch andere Packages oder Varianten ersetzt werden.
NlSemi bestimmt, ob \escape{n} und das Ende des Files zu ; übersetzt werden. Dies hat den Vorteil, dass manuell keine Strichpunkte mehr gesetzt werden müssen, da der Kompiler dies automatisch tut in jeder Neuen Zeile. Hier kann es aber zu Einschränkungen kommen. Geschweifte Klammern nach Kontrollstrukturen(if,switch) können nicht in die nächste Zeile gesetzt werden, da sonst ein Strichpunkt vom Compiler dahinter gesetzt werden würde. Eine einzelne geschweifte Klammer ist ein ungültiges Statement. Somit muss die geschweifte Klammer immer in der gleichen Zeile wie die Kontrollstruktur sein, da diese dort erwartet wird. 
Line und col ist die aktuelle Position des gelesenen Characters. Blank??????. Tok ist das resultierende Token. Lit wird benutzt, um zwischenzuspeichern, falls ein Name, ein Literal oder eine der drei Semicolon Fälle auftreten. Bad wird benutzt um zu kennzeichen, dass ein Syntax Error aufgetreten ist. Kind beschreibt die Art des Literals, falls dieses auftritt. Op und Prec speichern Werte, falls ein Operator, Star, AssignOp oder IncOp Token auftritt.

\begin{lstlisting}
// hash is a perfect hash function for keywords.
// It assumes that s has at least length 2.
func hash(s []byte) uint {
	return (uint(s[0])<<4 ^ uint(s[1]) + uint(len(s))) & uint(len(keywordMap)-1)
}

var keywordMap [1 << 6]token // size must be power of two

func init() {
	// populate keywordMap
	for tok := _Break; tok <= _Var; tok++ {
		h := hash([]byte(tok.String()))
		if keywordMap[h] != 0 {
			panic("imperfect hash")
		}
		keywordMap[h] = tok
	}
}

	// keywords(defined in tokens.go File)
	_Break       // break
	_Case        // case
	_Chan        // chan
	_Const       // const
	_Continue    // continue
	_Default     // default
	_Defer       // defer
	_Else        // else
	_Fallthrough // fallthrough
	_For         // for
	_Func        // func
	_Go          // go
	_Goto        // goto
	_If          // if
	_Import      // import
	_Interface   // interface
	_Map         // map
	_Package     // package
	_Range       // range
	_Return      // return
	_Select      // select
	_Struct      // struct
	_Switch      // switch
	_Type        // type
	_Var         // var
\end{lstlisting}
Folgende Funktionen werden für die Initialisierung einer Keyword map benutzt, die später benötigt wird um zu testen, ob ein es sich um ein Keyword Token handelt. Zunächst werden alle möglichen Keywords als Constant strings definiert und in der Datei token\_string.go einen Int Wert zugewiesen, der sich pro Zeile um eins inkrementiert. Somit werden in der For Schleife alle Keywords durchlaufen und für jedes an einer Stelle gespeichert. Diese Stelle wird mit einer Hash Funktion generiert, die Kollisionen vermeiden soll.

Die Funktion next liest den nächsten Token. Zuerst wird ein lokales nlsemi erstellt, dass auf das nlsemi des Scanners gesetzt wird. Dieses wird dann auf falsch gesetzt. Das Label redo und das Label assignop wird definiert. Danach werden alle whitespace Character übersprungen. Der Scanner wird auf den Start des tatsächlichen Tokens eingestellt. Einige Fälle werden vorher seperat abgedeckt. Momentan wird sich der erste Character des Token angeschaut. 
\begin{lstlisting}
func (s *scanner) atIdentChar(first bool) bool {
	switch {
	case unicode.IsLetter(s.ch) || s.ch == '_':
		// ok
	case unicode.IsDigit(s.ch):
		if first {
			s.errorf("identifier cannot begin with digit %#U", s.ch)
		}
	case s.ch >= utf8.RuneSelf:
		s.errorf("invalid character %#U in identifier", s.ch)
	default:
		return false
	}
	return true
}
\end{lstlisting}
Die Funktion atIdentChar bestimmt, dass ein Token nicht mit einer Zahl beginnen darf. Buchstaben oder '\_' sind dort in Ordnung. Wenn der Character größer als utf8.RuneSelf ist, dann wird davon ausgegangen, dass ist der Character außerhalb der gültigen Zeichen. In beiden Fällen wird ein Fehler ausgegeben. Werden diese Regeln eingehalten, dann kann sich der nächste Character angeschaut werden.
\begin{lstlisting}
    func (s *scanner) ident() {
	// accelerate common case (7bit ASCII)
	for isLetter(s.ch) || isDecimal(s.ch) {
		s.nextch()
	}

	// general case
	if s.ch >= utf8.RuneSelf {
		for s.atIdentChar(false) {
			s.nextch()
		}
	}

	// possibly a keyword
	lit := s.segment()
	if len(lit) >= 2 {
		if tok := keywordMap[hash(lit)]; tok != 0 && tokStrFast(tok) == string(lit) {
			s.nlsemi = contains(1<<_Break|1<<_Continue|1<<_Fallthrough|1<<_Return, tok)
			s.tok = tok
			return
		}
	}

	s.nlsemi = true
	s.lit = string(lit)
	s.tok = _Name
}
\end{lstlisting}
Für die nächsten Character wird die Funktion ident benutzt. Solange auf den ersten Character Buchstaben und Zahlen folgen, wird der Character übersprungen. Wenn das Zeichen ungültig ist weil es größer als utf8.RuneSelf ist, dann wird ebenfalls wieder ein Fehler ausgegeben. 
Wenn das Wort zu Ende ist, wird geprüft ob es mehr als einen Character hat. Ist dies der Fall, hat man ein Keyword gefunden und das Token wird dementsprechend gesetzt.\\
\\Weiterhin folgen einige speziellere Fälle, die mit einem Switch Case Statement durchlaufen werden. Diese lassen sich weiter aufteilen in die Kommentare und Pragmas, Operatoren Zeichen und zu Letzt alle weiteren Zeichen, die benutzt werden.  
\begin{lstlisting}
case '/':
		s.nextch()
		if s.ch == '/' {
			s.nextch()
			s.lineComment()
			goto redo
		}
		if s.ch == '*' {
			s.nextch()
			s.fullComment()
			if line, _ := s.pos(); line > s.line && nlsemi {
				// A multi-line comment acts like a newline;
				// it translates to a ';' if nlsemi is set.
				s.lit = "newline"
				s.tok = _Semi
				break
			}
			goto redo
		}
		s.op, s.prec = Div, precMul
		goto assignop

\end{lstlisting}
Für den einzeiligen Kommentar // wird die Funktion lineComment aufgerufen.
\begin{lstlisting}
func (s *scanner) lineComment() {

	if s.mode&comments != 0 {
		s.skipLine()
		s.comment(string(s.segment()))
		return
	}

	// are we saving directives? or is this definitely not a directive?
	if s.mode&directives == 0 || (s.ch != 'g' && s.ch != 'l') {
		s.stop()
		s.skipLine()
		return
	}

	// recognize go: or line directives
	prefix := "go:"
	if s.ch == 'l' {
		prefix = "line "
	}
	for _, m := range prefix {
		if s.ch != m {
			s.stop()
			s.skipLine()
			return
		}
		s.nextch()
	}

	// directive text
	s.skipLine()
	s.comment(string(s.segment()))
}
\end{lstlisting}
Ist mode so gesetzt, dass Kommentare Fehler zurückgeben, wird dies hier getan mit der Funktion comment. Zusätzlich muss skipLine aufgerufen werden. Diese Funktion stellt sicher, dass der Character \\n übersprungen wird. Dieser wird benötigt, um die Logik für nlsemi umzusetzen. Wenn mode auf nur Directives gesetzt ist, wird überprüft ob es sich um eine handelt. Diese müsste mit //go: oder mit \\l (für \\line:) starten. Ist dies nicht der Fall, wird die Funktion stop aufgerufen. Wird trotzdem eine Directive erkannt, wird diese als Fehler zurückgegeben.\\
\\Mehrzeilige Kommentare werden genauso behandelt wie eine neue Zeile. Ein Unterschied ist in der Full Comment Funktion.
\begin{lstlisting}
// recognize line directive
	const prefix = "line "
	for _, m := range prefix {
		if s.ch != m {
			s.stop()
			s.skipComment()
			return
		}
		s.nextch()
	}
\end{lstlisting}
Hier muss auf die line Directive geachtet werden.\\
\\Ist kein // vorhanden sondern nur ein einzelner /, muss es sich um einen Operator handeln und dementsprechend wird dorthin gesprungen. 

\begin{lstlisting}
case '\n':
		s.nextch()
		s.lit = "newline"
		s.tok = _Semi
\end{lstlisting}
Neue Zeilen werden so direkt eingelesen
\begin{lstlisting}
	case '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':
		s.number(false)
        
    func (s *scanner) number(seenPoint bool) {
	ok := true
	kind := IntLit
	base := 10        // number base
	prefix := rune(0) // one of 0 (decimal), '0' (0-octal), 'x', 'o', or 'b'
	digsep := 0       // bit 0: digit present, bit 1: '_' present
	invalid := -1     // index of invalid digit in literal, or < 0

	// integer part
	if !seenPoint {
		if s.ch == '0' {
			s.nextch()
			switch lower(s.ch) {
			case 'x':
				s.nextch()
				base, prefix = 16, 'x'
			case 'o':
				s.nextch()
				base, prefix = 8, 'o'
			case 'b':
				s.nextch()
				base, prefix = 2, 'b'
			default:
				base, prefix = 8, '0'
				digsep = 1 // leading 0
			}
		}
		digsep |= s.digits(base, &invalid)
		if s.ch == '.' {
			if prefix == 'o' || prefix == 'b' {
				s.errorf("invalid radix point in %s literal", baseName(base))
				ok = false
			}
			s.nextch()
			seenPoint = true
		}
	}
\end{lstlisting}
Da Zahlen an Erster Stelle bereits behandelt wurden handelt es sich hier um eine weitere Ziffer. Somit muss hier entschieden werden, ob es sich um eine Kommazahl handelt. Ist eine weitere Ziffer erkannt, handelt es sich momentan um keine Kommazahl und die Funktion Number wird dementsprechend aufgerufen. In dieser wird standardmäßig die Basis als Dezimalzahl behandelt. Dies muss geändert werden, wenn auf den Character 0 ein weitere Character folgt, der keine Zahl ist. Für das Hexadezimal System ist dies x, für das Oktalsystem o und für das Binärsystem b. Digsep sagt aus ob ein Seperator vorhanden ist. 
Nach dem Richtigstellen der Basis, wird ein bitweises OR von digsep mit der Funktion digits durchgeführt. Diese Funktion gibt eine Zahl zurück, deren Bitmuster aussagt, ob ein Seperator vorhanden ist oder nicht. Ist das nullte Bit auf eins gesetzt, sind Zahlen vorhanden. Ist das erste Bit auf eins gesetzt, sind Seperatoren vorhanden. Wenn die Funktion die Integer Zahl drei zurückgibt, sind beide dieser Bits gesetzt und somit sind Zahlen und Seperatoren vorhanden. Dieses wird dann an die lokale dipsep Variable übertragen. Wenn der Seperator ein Dezimalpunkt ist, wird ein Fehler ausgegeben wenn die Zahl eine Oktal- oder Binärzahl ist. Daraufhin wird die Variable seenPoint auf true gesetzt und die es handelt sich um eine Kommazahl.
\begin{lstlisting}
if seenPoint {
		kind = FloatLit
		digsep |= s.digits(base, &invalid)
	}

	if digsep&1 == 0 && ok {
		s.errorf("%s literal has no digits", baseName(base))
		ok = false
	}
\end{lstlisting}
Wenn ein Punkt existiert, wird kind auf die Existenz eines Float Literals gesetzt. Standardmäßig ist dies auf IntLit also auf literals gesetzt, die bei Integer Zahlen vorkommen.
Wenn das nullte Bit auf null gesetzt ist das erste Bit aber auf eins, hier geprüft durch die Variable ok, dann gibt es einen Fehler da keine Zahlen und nur Seperatoren gefunden wurden.
\begin{lstlisting}
if e := lower(s.ch); e == 'e' || e == 'p' {
		if ok {
			switch {
			case e == 'e' && prefix != 0 && prefix != '0':
				s.errorf("%q exponent requires decimal mantissa", s.ch)
				ok = false
			case e == 'p' && prefix != 'x':
				s.errorf("%q exponent requires hexadecimal mantissa", s.ch)
				ok = false
			}
		}
		s.nextch()
		kind = FloatLit
		if s.ch == '+' || s.ch == '-' {
			s.nextch()
		}
		digsep = s.digits(10, nil) | digsep&2 // don't lose sep bit
		if digsep&1 == 0 && ok {
			s.errorf("exponent has no digits")
			ok = false
		}
	} else if prefix == 'x' && kind == FloatLit && ok {
		s.errorf("hexadecimal mantissa requires a 'p' exponent")
		ok = false
	}
\end{lstlisting}
Um Exponenten auszudrücken werden die Character e und p benutzt. Wenn der Character e vorhanden ist, muss die Zahl(Mantisse) vor dem Exponent eine Dezimalzahl sein. Wenn p benutzt wird, muss es eine Hexadezimalzahl sein.
Bei + oder - wird der Character übersprungen. Hier wird ebenfalls geprüft, ob nur Seperatoren und keine Zahlen vorhanden sind. Zusätzlich wird gefordert, dass eine Hexadezimalzahl einen Exponenten mit dem Character p startet. Der Character i kann ebenfalls noch vorkommen und in dem Fall gesetzt. 

Wenn eine Ziffer ungültig war, wird dieser Fall am Schlus geprüft und als Fehler ausgegeben. Ebenso wird mit der Hilfe invalidSep der erste ungültige Seperator ausgegeben. \\
\\
\begin{lstlisting}
case '(':
		s.nextch()
		s.tok = _Lparen

	case '[':
		s.nextch()
		s.tok = _Lbrack

	case '{':
		s.nextch()
		s.tok = _Lbrace

	case ',':
		s.nextch()
		s.tok = _Comma

	case ';':
		s.nextch()
		s.lit = "semicolon"
		s.tok = _Semi

	case ')':
		s.nextch()
		s.nlsemi = true
		s.tok = _Rparen

	case ']':
		s.nextch()
		s.nlsemi = true
		s.tok = _Rbrack

	case '}':
		s.nextch()
		s.nlsemi = true
		s.tok = _Rbrace
\end{lstlisting}
Klammern aller Art, das Komma und der Strichpunkt werden alle gekennzeichnet.
\begin{lstlisting}
	case ':':
		s.nextch()
		if s.ch == '=' {
			s.nextch()
			s.tok = _Define
			break
		}
		s.tok = _Colon
\end{lstlisting}
Der Doppelpunkt wird als Dopplepunkt gekennzeichnet, außer wenn darauf ein Istgleich Zeichen folgt. Dies ist der Define Operator, mit welchem Variablen definiert werden können.
\begin{lstlisting}
	case '.':
		s.nextch()
		if isDecimal(s.ch) {
			s.number(true)
			break
		}
		if s.ch == '.' {
			s.nextch()
			if s.ch == '.' {
				s.nextch()
				s.tok = _DotDotDot
				break
			}
			s.rewind() // now s.ch holds 1st '.'
			s.nextch() // consume 1st '.' again
		}
		s.tok = _Dot
\end{lstlisting}
Der Punkt wird als Kommapunkt gewertet, wenn darauf eine Dezimalzahl folgt. Wenn zwei weitere Punkte folgen wird es als ... Operator erkannt. Dieser wird die Definition einer variablen Anzahl von Parametern benutzt. Ansonsten wird es als Punkt gewertet, der z.B bei Zugriff auf Typ Methoden eingesetzt wird.\\
\\ Ein weitere größere Unterteilung bilden die Operatoren. Beginnend mit den Standardoperatoren + und -.
\begin{lstlisting}
case '+':
		s.nextch()
		s.op, s.prec = Add, precAdd
		if s.ch != '+' {
			goto assignop
		}
		s.nextch()
		s.nlsemi = true
		s.tok = _IncOp

	case '-':
		s.nextch()
		s.op, s.prec = Sub, precAdd
		if s.ch != '-' {
			goto assignop
		}
		s.nextch()
		s.nlsemi = true
		s.tok = _IncOp
\end{lstlisting}
Wenn nur ein einzelnes Zeichen existiert, wird zum Label AssignOp gesprungen.
\begin{lstlisting}
assignop:
	if s.ch == '=' {
		s.nextch()
		s.tok = _AssignOp
		return
	}
	s.tok = _Operator
\end{lstlisting}
Dieses prüft, ob es sich um den AssignOpertor handelt. Wenn nicht wird einfach nur der Token auf Operator gesetzt.\\
Kommen zwei + oder zwei - vor, dann wird dieses als Increment oder als Decrement Operator gewertet, der jeweils +1 oder -1 auf eine Variable rechnet.
\begin{lstlisting}
    case '*':
		s.nextch()
		s.op, s.prec = Mul, precMul
		// don't goto assignop - want _Star token
		if s.ch == '=' {
			s.nextch()
			s.tok = _AssignOp
			break
		}
		s.tok = _Star

	case '/':
		s.nextch()
		if s.ch == '/' {
			s.nextch()
			s.lineComment()
			goto redo
		}
		if s.ch == '*' {
			s.nextch()
			s.fullComment()
			if line, _ := s.pos(); line > s.line && nlsemi {
				// A multi-line comment acts like a newline;
				// it translates to a ';' if nlsemi is set.
				s.lit = "newline"
				s.tok = _Semi
				break
			}
			goto redo
		}
		s.op, s.prec = Div, precMul
		goto assignop
\end{lstlisting}
Wenn auf * oder / ein = folgt, dann wird dieses als Assign Operator gewertet. Für * wird extra das Token auf \_Star gesetzt. Für / wird der Assign Operator bei AssignOp gesetzt.
\begin{lstlisting}
	case '%':
		s.nextch()
		s.op, s.prec = Rem, precMul
		goto assignop
    case '^':
		s.nextch()
		s.op, s.prec = Xor, precAdd
		goto assignop
    
	case '~':
		s.nextch()
		s.op, s.prec = Tilde, 0
		s.tok = _Operator
\end{lstlisting}
Für die Operatoren \%, \^ und \~ werden nur die jeweiligen Operator Token gesetzt.
\begin{lstlisting}
case '<':
		s.nextch()
		if s.ch == '=' {
			s.nextch()
			s.op, s.prec = Leq, precCmp
			s.tok = _Operator
			break
		}
		if s.ch == '<' {
			s.nextch()
			s.op, s.prec = Shl, precMul
			goto assignop
		}
		if s.ch == '-' {
			s.nextch()
			s.tok = _Arrow
			break
		}
		s.op, s.prec = Lss, precCmp
		s.tok = _Operator

	case '>':
		s.nextch()
		if s.ch == '=' {
			s.nextch()
			s.op, s.prec = Geq, precCmp
			s.tok = _Operator
			break
		}
		if s.ch == '>' {
			s.nextch()
			s.op, s.prec = Shr, precMul
			goto assignop
		}
		s.op, s.prec = Gtr, precCmp
		s.tok = _Operator
\end{lstlisting}
< und > haben decken folgende Operatoren Fälle ab: >= und <=, >> und <<, zuletzt <-. 
\begin{lstlisting}
case '&':
		s.nextch()
		if s.ch == '&' {
			s.nextch()
			s.op, s.prec = AndAnd, precAndAnd
			s.tok = _Operator
			break
		}
		s.op, s.prec = And, precMul
		if s.ch == '^' {
			s.nextch()
			s.op = AndNot
		}
		goto assignop
case '|':
		s.nextch()
		if s.ch == '|' {
			s.nextch()
			s.op, s.prec = OrOr, precOrOr
			s.tok = _Operator
			break
		}
		s.op, s.prec = Or, precAdd
		goto assignop
\end{lstlisting}
Für | und \& werden sowohl die einzelnen Logik Operatoren als auch die doppelten \&\& und || zugewiesen. Zusätzlich existiert nicht der AndNot Operator \&\^.
\begin{lstlisting}
	case '=':
		s.nextch()
		if s.ch == '=' {
			s.nextch()
			s.op, s.prec = Eql, precCmp
			s.tok = _Operator
			break
		}
		s.tok = _Assign

	case '!':
		s.nextch()
		if s.ch == '=' {
			s.nextch()
			s.op, s.prec = Neq, precCmp
			s.tok = _Operator
			break
		}
		s.op, s.prec = Not, 0
		s.tok = _Operator

\end{lstlisting}
Zuletzt gibt es noch den Equal Operator ==, der im Fall eines einzelnen = ein Assign Operator ist. Für ! existiert der Not Operator ! und der Not Equal Operator !=. \\
\\ Zuletzt werden noch die String Methoden " ' und ` mit jeweils eigenen Methoden erkannt.
\begin{lstlisting}
	case '"':
		s.stdString()

	case '`':
		s.rawString()

	case '\'':
		s.rune()

func (s *scanner) stdString() {
	ok := true
	s.nextch()

	for {
		if s.ch == '"' {
			s.nextch()
			break
		}
		if s.ch == '\\' {
			s.nextch()
			if !s.escape('"') {
				ok = false
			}
			continue
		}
		if s.ch == '\n' {
			s.errorf("newline in string")
			ok = false
			break
		}
		if s.ch < 0 {
			s.errorAtf(0, "string not terminated")
			ok = false
			break
		}
		s.nextch()
	}

	s.setLit(StringLit, ok)
\end{lstlisting}
Für den Standard String "" werden einige Fälle definiert. Wenn direkt der zweite " folgt dann ist es der leere String und es kann abgebrochen werden. Falls ein Backslash in dem String alleine vorkommt, ist dies ein Escape Zeichen und die Funktion wird aufgerufen. In diesem Fall gibt diese aber nur true zurück. 
Existiert ein Whitespace in dem String wird ein Fehler ausgeworfen, dass eine neue Zeile im String enthalten ist. Falls kein zweites " mehr folgt, wird der Fehler ausgeworfen dass der String nicht terminiert wurde.
\begin{lstlisting}
func (s *scanner) rawString() {
	ok := true
	s.nextch()

	for {
		if s.ch == '`' {
			s.nextch()
			break
		}
		if s.ch < 0 {
			s.errorAtf(0, "string not terminated")
			ok = false
			break
		}
		s.nextch()
	}
	// We leave CRs in the string since they are part of the
	// literal (even though they are not part of the literal
	// value).

	s.setLit(StringLit, ok)
}
\end{lstlisting}
Für den raw String existiert der leere String `` oder der nicht terminierte String.
\begin{lstlisting}
unc (s *scanner) rune() {
	ok := true
	s.nextch()

	n := 0
	for ; ; n++ {
		if s.ch == '\'' {
			if ok {
				if n == 0 {
					s.errorf("empty rune literal or unescaped '")
					ok = false
				} else if n != 1 {
					s.errorAtf(0, "more than one character in rune literal")
					ok = false
				}
			}
			s.nextch()
			break
		}
		if s.ch == '\\' {
			s.nextch()
			if !s.escape('\'') {
				ok = false
			}
			continue
		}
		if s.ch == '\n' {
			if ok {
				s.errorf("newline in rune literal")
				ok = false
			}
			break
		}
		if s.ch < 0 {
			if ok {
				s.errorAtf(0, "rune literal not terminated")
				ok = false
			}
			break
		}
		s.nextch()
	}
\end{lstlisting}
Für die rune Funktion gibt es ähnliche Fälle. Die leere Rune ist nicht gültig. Somit wird dies geprüft genauso weil der Fall wenn mehr als ein Character in einer Rune enthalten ist. Weiterhin gibt es den Escape mit Backslash, die Neue Zeile mit Whitespace und den Fall dass das Rune literal nicht terminiert wurde.
\begin{lstlisting}
p.scanner.init(
		r,
		// Error and directive handler for scanner.
		// Because the (line, col) positions passed to the
		// handler is always at or after the current reading
		// position, it is safe to use the most recent position
		// base to compute the corresponding Pos value.
		func(line, col uint, msg string) {
			if msg[0] != '/' {
				p.errorAt(p.posAt(line, col), msg)
				return
			}

			// otherwise it must be a comment containing a line or go: directive.
			// //line directives must be at the start of the line (column colbase).
			// /*line*/ directives can be anywhere in the line.
			text := commentText(msg)
			if (col == colbase || msg[1] == '*') && strings.HasPrefix(text, "line ") {
				var pos Pos // position immediately following the comment
				if msg[1] == '/' {
					// line comment (newline is part of the comment)
					pos = MakePos(p.file, line+1, colbase)
				} else {
					// regular comment
					// (if the comment spans multiple lines it's not
					// a valid line directive and will be discarded
					// by updateBase)
					pos = MakePos(p.file, line, col+uint(len(msg)))
				}
				p.updateBase(pos, line, col+2+5, text[5:]) // +2 to skip over // or /*
				return
			}

			// go: directive (but be conservative and test)
			if strings.HasPrefix(text, "go:") {
				if p.top && strings.HasPrefix(msg, "//go:build") {
					if x, err := constraint.Parse(msg); err == nil {
						p.goVersion = constraint.GoVersion(x)
					}
				}
				if pragh != nil {
					p.pragma = pragh(p.posAt(line, col+2), p.scanner.blank, text, p.pragma) // +2 to skip over // or /*
				}
			}
		},
		directives,
	)

	p.base = file
	p.first = nil
	p.errcnt = 0
	p.pragma = nil

	p.fnest = 0
	p.xnest = 0
	p.indent = nil
}
\end{lstlisting}
Bevor der Parser übernimmt, wird in dem parser.go File der Scanner initialisiert. Hierzu wird als Source der Io Reader genutzt, der dem Parser übergeben wurde. Als nächstes müssen Error und Directive Handler definiert werden. Für den Error Handler reicht eine einfacher Prüfung, ob eine Nachricht gesetzt wurde. Dann kann ein Fehler mit aktueller Position ausgegeben werden. Für den Directive Handler wird zuerst nach line( //line) Directives geprüft. Dazu muss die Directive am Anfang der Linie starten. Somit muss die aktuelle Spalte der Spaltenbasis gleichen oder die msg enthalt einen Stern an zweiter Positon, um die Directive /*line*/ abzudecken, die überall in der Zeile vorkommen kann. Funktion MakePos findet die Position nach dem Ende der Directive und aktualisiert pos. Update Base kümmert sich um die Aktualisierung der Positionsbasis, die Feld des Parsers ist. Danach werden die directives übergeben.Ab hier übernimmt nun der Parser.

\subsection{nur mit Text ohne Listings}
In der Syntax.go Datei wird die Funktion Parse definiert. Diese Definiert einen Parser und ruft dann dessen Initialisierungsfunktion auf. Danach wird der Parser auf das nächste Token geschalten. 
Der Parser ruft die Scanner init- Funktion auf. Der Scanner selbst ist definiert in der scanner.go Datei, der Parser hingegen in der Parser.Go Datei. Alle drei Dateien sind in dem Ordner src/cmd/compile/internal/syntax. 
\cite{donovan_go_2016}

Der Scanner besitzt einige Felder zum identifizieren von Token. 
Source wird mit dem IO Stream des zu scannenden Textes übergeben.
Die mode flags kontrollieren welche Kommentare als Fehler geflaged werden. 
Bei nicht Setzung werden alle Kommentare ignoriert. Bei Setzen auf 1 werden alle Kommentare an den Error Handler übergeben, bei Setzen auf 2 nur die directives. Directives in Go sind spezifische Compiler Instruktionen, die ebenfalls mit // beginnen. Diese können überallhin platziert werden. Die Syntax ist //go:directive. Pragmas und Directives sind Synonyme. Benutzen von diesen ist generell eher unerwünscht. Diese sind frühere Implementierungen und sollten eher durch andere Packages oder Varianten ersetzt werden.
NlSemi bestimmt, ob \escape{n} und das Ende des Files zu ; übersetzt werden. Dies hat den Vorteil, dass manuell keine Strichpunkte mehr gesetzt werden müssen, da der Kompiler dies automatisch tut in jeder Neuen Zeile. Hier kann es aber zu Einschränkungen kommen. Geschweifte Klammern nach Kontrollstrukturen(if,switch) können nicht in die nächste Zeile gesetzt werden, da sonst ein Strichpunkt vom Compiler dahinter gesetzt werden würde. Eine einzelne geschweifte Klammer ist ein ungültiges Statement. Somit muss die geschweifte Klammer immer in der gleichen Zeile wie die Kontrollstruktur sein, da diese dort erwartet wird. 
Line und col ist die aktuelle Position des gelesenen Characters. Blank??????. Tok ist das resultierende Token. Lit wird benutzt, um zwischenzuspeichern, falls ein Name, ein Literal oder eine der drei Semicolon Fälle auftreten. Bad wird benutzt um zu kennzeichen, dass ein Syntax Error aufgetreten ist. Kind beschreibt die Art des Literals, falls dieses auftritt. Op und Prec speichern Werte, falls ein Operator, Star, AssignOp oder IncOp Token auftritt.

Folgende Funktionen werden für die Initialisierung einer Keyword map benutzt, die später benötigt wird um zu testen, ob ein es sich um ein Keyword Token handelt. Zunächst werden alle möglichen Keywords als Constant strings definiert und in der Datei token\_string.go einen Int Wert zugewiesen, der sich pro Zeile um eins inkrementiert. Somit werden in der For Schleife alle Keywords durchlaufen und für jedes an einer Stelle gespeichert. Diese Stelle wird mit einer Hash Funktion generiert, die Kollisionen vermeiden soll. Die Funktion next liest den nächsten Token. Zuerst wird ein lokales nlsemi erstellt, dass auf das nlsemi des Scanners gesetzt wird. Dieses wird dann auf falsch gesetzt. Das Label redo und das Label assignop wird definiert. Danach werden alle whitespace Character übersprungen. Der Scanner wird auf den Start des tatsächlichen Tokens eingestellt. Einige Fälle werden vorher seperat abgedeckt. Momentan wird sich der erste Character des Token angeschaut. Die Funktion atIdentChar bestimmt, dass ein Token nicht mit einer Zahl beginnen darf. Buchstaben oder '\_' sind dort in Ordnung. Wenn der Character größer als utf8.RuneSelf ist, dann wird davon ausgegangen, dass ist der Character außerhalb der gültigen Zeichen. In beiden Fällen wird ein Fehler ausgegeben. Werden diese Regeln eingehalten, dann kann sich der nächste Character angeschaut werden.

Für die nächsten Character wird die Funktion ident benutzt. Solange auf den ersten Character Buchstaben und Zahlen folgen, wird der Character übersprungen. Wenn das Zeichen ungültig ist weil es größer als utf8.RuneSelf ist, dann wird ebenfalls wieder ein Fehler ausgegeben. 
Wenn das Wort zu Ende ist, wird geprüft ob es mehr als einen Character hat. Ist dies der Fall, hat man ein Keyword gefunden und das Token wird dementsprechend gesetzt.\\
\\Weiterhin folgen einige speziellere Fälle, die mit einem Switch Case Statement durchlaufen werden. Diese lassen sich weiter aufteilen in die Kommentare und Pragmas, Operatoren Zeichen und zu Letzt alle weiteren Zeichen, die benutzt werden.
Für den einzeiligen Kommentar // wird die Funktion lineComment aufgerufen.

Ist mode so gesetzt, dass Kommentare Fehler zurückgeben, wird dies hier getan mit der Funktion comment. Zusätzlich muss skipLine aufgerufen werden. Diese Funktion stellt sicher, dass der Character \\n übersprungen wird. Dieser wird benötigt, um die Logik für nlsemi umzusetzen. Wenn mode auf nur Directives gesetzt ist, wird überprüft ob es sich um eine handelt. Diese müsste mit //go: oder mit \\l (für \\line:) starten. Ist dies nicht der Fall, wird die Funktion stop aufgerufen. Wird trotzdem eine Directive erkannt, wird diese als Fehler zurückgegeben.\\
\\Mehrzeilige Kommentare werden genauso behandelt wie eine neue Zeile. Ein Unterschied ist in der Full Comment Funktion.
Hier muss auf die line Directive geachtet werden.
\\Ist kein // vorhanden sondern nur ein einzelner /, muss es sich um einen Operator handeln und dementsprechend wird dorthin gesprungen. 

Neue Zeilen werden so direkt eingelesen
Da Zahlen an Erster Stelle bereits behandelt wurden handelt es sich hier um eine weitere Ziffer. Somit muss hier entschieden werden, ob es sich um eine Kommazahl handelt. Ist eine weitere Ziffer erkannt, handelt es sich momentan um keine Kommazahl und die Funktion Number wird dementsprechend aufgerufen. In dieser wird standardmäßig die Basis als Dezimalzahl behandelt. Dies muss geändert werden, wenn auf den Character 0 ein weitere Character folgt, der keine Zahl ist. Für das Hexadezimal System ist dies x, für das Oktalsystem o und für das Binärsystem b. Digsep sagt aus ob ein Seperator vorhanden ist. 
Nach dem Richtigstellen der Basis, wird ein bitweises OR von digsep mit der Funktion digits durchgeführt. Diese Funktion gibt eine Zahl zurück, deren Bitmuster aussagt, ob ein Seperator vorhanden ist oder nicht. Ist das nullte Bit auf eins gesetzt, sind Zahlen vorhanden. Ist das erste Bit auf eins gesetzt, sind Seperatoren vorhanden. Wenn die Funktion die Integer Zahl drei zurückgibt, sind beide dieser Bits gesetzt und somit sind Zahlen und Seperatoren vorhanden. Dieses wird dann an die lokale dipsep Variable übertragen. Wenn der Seperator ein Dezimalpunkt ist, wird ein Fehler ausgegeben wenn die Zahl eine Oktal- oder Binärzahl ist. Daraufhin wird die Variable seenPoint auf true gesetzt und die es handelt sich um eine Kommazahl.

Wenn ein Punkt existiert, wird kind auf die Existenz eines Float Literals gesetzt. Standardmäßig ist dies auf IntLit also auf literals gesetzt, die bei Integer Zahlen vorkommen.
Wenn das nullte Bit auf null gesetzt ist das erste Bit aber auf eins, hier geprüft durch die Variable ok, dann gibt es einen Fehler da keine Zahlen und nur Seperatoren gefunden wurden.

Um Exponenten auszudrücken werden die Character e und p benutzt. Wenn der Character e vorhanden ist, muss die Zahl(Mantisse) vor dem Exponent eine Dezimalzahl sein. Wenn p benutzt wird, muss es eine Hexadezimalzahl sein.
Bei + oder - wird der Character übersprungen. Hier wird ebenfalls geprüft, ob nur Seperatoren und keine Zahlen vorhanden sind. Zusätzlich wird gefordert, dass eine Hexadezimalzahl einen Exponenten mit dem Character p startet. Der Character i kann ebenfalls noch vorkommen und in dem Fall gesetzt. 

Wenn eine Ziffer ungültig war, wird dieser Fall am Schlus geprüft und als Fehler ausgegeben. Ebenso wird mit der Hilfe invalidSep der erste ungültige Seperator ausgegeben. \\
Klammern aller Art, das Komma und der Strichpunkt werden alle gekennzeichnet.
Der Doppelpunkt wird als Dopplepunkt gekennzeichnet, außer wenn darauf ein Istgleich Zeichen folgt. Dies ist der Define Operator, mit welchem Variablen definiert werden können.
Der Punkt wird als Kommapunkt gewertet, wenn darauf eine Dezimalzahl folgt. Wenn zwei weitere Punkte folgen wird es als ... Operator erkannt. Dieser wird die Definition einer variablen Anzahl von Parametern benutzt. Ansonsten wird es als Punkt gewertet, der z.B bei Zugriff auf Typ Methoden eingesetzt wird.\\
\\ Ein weitere größere Unterteilung bilden die Operatoren. Beginnend mit den Standardoperatoren + und -.

Wenn nur ein einzelnes Zeichen existiert, wird zum Label AssignOp gesprungen.
Dieses prüft, ob es sich um den AssignOpertor handelt. Wenn nicht wird einfach nur der Token auf Operator gesetzt.\\
Kommen zwei + oder zwei - vor, dann wird dieses als Increment oder als Decrement Operator gewertet, der jeweils +1 oder -1 auf eine Variable rechnet.
Wenn auf * oder / ein = folgt, dann wird dieses als Assign Operator gewertet. Für * wird extra das Token auf \_Star gesetzt. Für / wird der Assign Operator bei AssignOp gesetzt.
Für die Operatoren \%, \^ und \~ werden nur die jeweiligen Operator Token gesetzt.
< und > haben decken folgende Operatoren Fälle ab: >= und <=, >> und <<, zuletzt <-. 
Für | und \& werden sowohl die einzelnen Logik Operatoren als auch die doppelten \&\& und || zugewiesen. Zusätzlich existiert nicht der AndNot Operator \&\^.

Zuletzt gibt es noch den Equal Operator ==, der im Fall eines einzelnen = ein Assign Operator ist. Für ! existiert der Not Operator ! und der Not Equal Operator !=. \\
\\ Zuletzt werden noch die String Methoden " ' und ` mit jeweils eigenen Methoden erkannt.

Für den Standard String "" werden einige Fälle definiert. Wenn direkt der zweite " folgt dann ist es der leere String und es kann abgebrochen werden. Falls ein Backslash in dem String alleine vorkommt, ist dies ein Escape Zeichen und die Funktion wird aufgerufen. In diesem Fall gibt diese aber nur true zurück. Existiert ein Whitespace in dem String wird ein Fehler ausgeworfen, dass eine neue Zeile im String enthalten ist. Falls kein zweites " mehr folgt, wird der Fehler ausgeworfen dass der String nicht terminiert wurde. Für den raw String existiert der leere String `` oder der nicht terminierte String.

Für die rune Funktion gibt es ähnliche Fälle. Die leere Rune ist nicht gültig. Somit wird dies geprüft genauso weil der Fall wenn mehr als ein Character in einer Rune enthalten ist. Weiterhin gibt es den Escape mit Backslash, die Neue Zeile mit Whitespace und den Fall dass das Rune literal nicht terminiert wurde.

Bevor der Parser übernimmt, wird in dem parser.go File der Scanner initialisiert. Hierzu wird als Source der Io Reader genutzt, der dem Parser übergeben wurde. Als nächstes müssen Error und Directive Handler definiert werden. Für den Error Handler reicht eine einfacher Prüfung, ob eine Nachricht gesetzt wurde. Dann kann ein Fehler mit aktueller Position ausgegeben werden. Für den Directive Handler wird zuerst nach line( //line) Directives geprüft. Dazu muss die Directive am Anfang der Linie starten. Somit muss die aktuelle Spalte der Spaltenbasis gleichen oder die msg enthalt einen Stern an zweiter Positon, um die Directive /*line*/ abzudecken, die überall in der Zeile vorkommen kann. Funktion MakePos findet die Position nach dem Ende der Directive und aktualisiert pos. Update Base kümmert sich um die Aktualisierung der Positionsbasis, die Feld des Parsers ist. Danach werden die directives übergeben.Ab hier übernimmt nun der Parser.